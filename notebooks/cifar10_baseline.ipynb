{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f395735f",
   "metadata": {},
   "source": [
    "# CIFAR-10 Baseline (Colab)\n",
    "\n",
    "This notebook loads the repo, installs deps, optionally runs the trainer, and visualizes saved metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a17eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3809b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setup: clone repo and install requirements\n",
    "%cd /content  # go back to root\n",
    "!rm -rf mixture-of-experts-project\n",
    "!git clone https://github.com/moe-project-uu/mixture-of-experts-project.git || true\n",
    "%cd mixture-of-experts-project\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# 2) Use Colab’s preinstalled torch to avoid CUDA mismatches\n",
    "#    (so don't reinstall torch/torchvision). Install your package + other deps.\n",
    "%pip install -U pip\n",
    "%pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b91bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load metrics and model checkpoint ---\n",
    "import os, torch, matplotlib.pyplot as plt\n",
    "\n",
    "# Choose the layer and run tag you used during training\n",
    "FF_LAYER = \"Dense\"              # e.g. \"Dense\", \"SoftMoE\", \"SparseMoE\"\n",
    "RUN_TAG  = \"W512-S42\"           # matches run_tag from training script\n",
    "\n",
    "base_dir = os.path.join(\"checkpoints\", FF_LAYER, RUN_TAG)\n",
    "metrics_path = os.path.join(base_dir, \"metrics.pt\")\n",
    "ckpt_path    = os.path.join(base_dir, \"model.pt\")\n",
    "summary_path = os.path.join(base_dir, \"summary.json\")\n",
    "\n",
    "# --- Load metrics safely ---\n",
    "metrics = torch.load(metrics_path, map_location=\"cpu\")\n",
    "train_losses = metrics.get(\"train_losses\", [])\n",
    "train_accs   = metrics.get(\"train_accs\", [])\n",
    "val_losses   = metrics.get(\"val_losses\", [])\n",
    "val_accs     = metrics.get(\"val_accs\", [])\n",
    "test_losses  = metrics.get(\"test_losses\", [])\n",
    "test_accs    = metrics.get(\"test_accs\", [])\n",
    "\n",
    "# --- Load checkpoint and summary for final results ---\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\") if os.path.exists(ckpt_path) else {}\n",
    "final_train_acc = (train_accs[-1] * 100) if len(train_accs) else float(\"nan\")\n",
    "final_test_acc  = ckpt.get(\"test_acc\", (test_accs[-1] * 100) if len(test_accs) else float(\"nan\"))\n",
    "\n",
    "# --- Plot loss curves ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "if val_losses: plt.plot(val_losses, label=\"val loss\")\n",
    "if test_losses: plt.plot(test_losses, label=\"test loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.legend(); plt.title(f\"{FF_LAYER} | Loss Curve\")\n",
    "plt.show()\n",
    "\n",
    "# --- Plot accuracy curves ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot([x * 100 for x in train_accs], label=\"train acc %\")\n",
    "if val_accs: plt.plot([x * 100 for x in val_accs], label=\"val acc %\")\n",
    "if test_accs: plt.plot([x * 100 for x in test_accs], label=\"test acc %\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy (%)\")\n",
    "plt.legend(); plt.title(f\"{FF_LAYER} | Accuracy Curve\")\n",
    "\n",
    "# --- Add final results as a text box ---\n",
    "textstr = f\"Final Train Acc: {final_train_acc:.2f}%\\nFinal Test Acc: {final_test_acc:.2f}%\"\n",
    "plt.gca().text(\n",
    "    0.95, 0.05, textstr,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=10, va=\"bottom\", ha=\"right\",\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986277f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL3: Loss/Accuracy curves from `hist`\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = np.array(hist[\"train_loss\"])\n",
    "train_acc  = np.array(hist[\"train_acc\"])\n",
    "val_loss   = np.array(hist[\"val_loss\"])\n",
    "val_acc    = np.array(hist[\"val_acc\"])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(val_loss,   label=\"val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(f'{args.FF_layer} — Loss'); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_acc, label=\"train\")\n",
    "plt.plot(val_acc,   label=\"val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(f'{args.FF_layer} — Accuracy'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL4: SoftMoE — Expert utilization over epochs + per-expert bars at a few epochs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if args.FF_layer != \"SoftMoE\":\n",
    "    print(\"Utilization plots are only available for SoftMoE. Re-run with args.FF_layer='SoftMoE'.\")\n",
    "else:\n",
    "    util_list = hist.get(\"util_per_epoch\", [])\n",
    "    assert len(util_list) > 0, \"No utilization recorded — ensure you trained with SoftMoE.\"\n",
    "\n",
    "    util = np.stack(util_list, axis=0)  # shape: (num_epochs, num_experts)\n",
    "\n",
    "    # (A) line plot: one curve per expert across epochs\n",
    "    plt.figure(figsize=(7,4))\n",
    "    for i in range(util.shape[1]):\n",
    "        plt.plot(util[:, i], label=f\"expert {i}\")\n",
    "    plt.xlabel(\"epoch\"); plt.ylabel(\"mean p_i\")\n",
    "    plt.title(\"Expert Utilization over epochs\")\n",
    "    plt.legend(ncol=2); plt.show()\n",
    "\n",
    "    # (B) one-bar-per-expert “histograms” at epochs ~0, 50, 100 (clamped to available range)\n",
    "    want = [0, 50, 100]\n",
    "    max_idx = util.shape[0] - 1\n",
    "    picked = [e for e in want if e <= max_idx]\n",
    "\n",
    "    for e in picked:\n",
    "        vals = util[e]  # length = num_experts\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.bar(np.arange(len(vals)), vals)\n",
    "        plt.xticks(np.arange(len(vals)), [f\"E{i}\" for i in range(len(vals))])\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel(\"mean p_i\"); plt.xlabel(\"expert\")\n",
    "        plt.title(f\"Expert mean probabilities at epoch index {e} (0-based)\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277ca80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95217b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
