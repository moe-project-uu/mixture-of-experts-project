{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bcc396",
   "metadata": {},
   "source": [
    "## Notebook for testing MoE with MNIST  \n",
    "Main objective here is to figure out how to get the gradients to go through the loss function using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11921873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\caleb\\\\OneDrive - Uppsala universitet\\\\Fall 2025\\\\Projects Course\\\\mixture-of-experts-organization\\\\mixture-of-experts-project', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\python313.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for the disk_memoize function\n",
    "import pickle\n",
    "import hashlib\n",
    "from functools import wraps\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add scripts folder path so I can get load_mnist\n",
    "repo_root = os.path.abspath(\"..\")  # one level up from /notebook\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "from scripts.MNIST import load_mnist\n",
    "print(sys.path)\n",
    "\n",
    "#just some basic stuff to set for reproducability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff8e5d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 980/980 [00:03<00:00, 287.81it/s]\n",
      "100%|██████████| 1135/1135 [00:03<00:00, 307.95it/s]\n",
      "100%|██████████| 1032/1032 [00:03<00:00, 282.57it/s]\n",
      "100%|██████████| 1010/1010 [00:03<00:00, 291.87it/s]\n",
      "100%|██████████| 982/982 [00:03<00:00, 318.64it/s]\n",
      "100%|██████████| 892/892 [00:03<00:00, 277.85it/s]\n",
      "100%|██████████| 958/958 [00:02<00:00, 325.49it/s]\n",
      "100%|██████████| 1028/1028 [00:03<00:00, 295.71it/s]\n",
      "100%|██████████| 974/974 [00:03<00:00, 310.53it/s]\n",
      "100%|██████████| 1009/1009 [00:03<00:00, 309.01it/s]\n",
      "100%|██████████| 10/10 [00:33<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving train images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5923/5923 [00:20<00:00, 290.92it/s]\n",
      "100%|██████████| 6742/6742 [00:25<00:00, 267.41it/s]\n",
      "100%|██████████| 5958/5958 [00:21<00:00, 278.58it/s]\n",
      "100%|██████████| 6131/6131 [00:24<00:00, 249.93it/s]\n",
      "100%|██████████| 5842/5842 [00:20<00:00, 282.54it/s]\n",
      "100%|██████████| 5421/5421 [00:15<00:00, 342.80it/s]\n",
      "100%|██████████| 5918/5918 [00:17<00:00, 329.50it/s]\n",
      "100%|██████████| 6265/6265 [00:15<00:00, 403.19it/s]\n",
      "100%|██████████| 5851/5851 [00:15<00:00, 370.79it/s]\n",
      "100%|██████████| 5949/5949 [00:17<00:00, 341.42it/s]\n",
      "100%|██████████| 10/10 [03:14<00:00, 19.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#want to get the data in a linear format becuase our simple MoE will be with linear layers\n",
    "def get_data(linear = True):\n",
    "    #get the train and test data from the dataset\n",
    "    xtrain,ytrain,xtest,ytest = load_mnist.load_mnist()\n",
    "    #if we want to work with flattened/ linear input\n",
    "    if linear:\n",
    "        xtrain = torch.Tensor(xtrain).to(DEVICE)\n",
    "        ytrain = torch.Tensor(ytrain).to(DEVICE)\n",
    "        xtest = torch.Tensor(xtest).to(DEVICE)\n",
    "        ytest = torch.Tensor(ytest).to(DEVICE)\n",
    "    else:\n",
    "        #converting to Tensors for easy PyTorch implementation and reshape for a CNN\n",
    "        xtrain = torch.Tensor(xtrain).reshape(60000, 1,28,28).to(DEVICE)\n",
    "        ytrain = torch.Tensor(ytrain).to(DEVICE)\n",
    "        xtest = torch.Tensor(xtest).reshape(10000, 1,28,28).to(DEVICE)\n",
    "        ytest = torch.Tensor(ytest).to(DEVICE)\n",
    "    #first we want to put our data in a pytorch dataset so we can mini batch and enumerate through it later more easily\n",
    "    train_dataset = torch.utils.data.TensorDataset(xtrain, ytrain)\n",
    "    test_dataset = torch.utils.data.TensorDataset(xtest, ytest)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "#get the datasets\n",
    "train_dataset, test_dataset = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e39a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dataloader for this specific CNN which is a wrapper around the Dataset for easy use\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=60000, shuffle=True)\n",
    "#make the batch size for the test DataLoader the size of the dataset for evaluation.\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = test_dataset.tensors[0].shape[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376ff1",
   "metadata": {},
   "source": [
    "Below I really want to try and understand how backpropagation with PyTorch so I can try and implement a SoftMoE model. So we are looking in depth at just a one layer NN and then will try and figure out how this can be implemented with a gating mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "943de75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the Training Loop\n",
      "Loss:  tensor(2.3030, grad_fn=<DivBackward1>)\n",
      "After zero grad\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0287,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0026, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0442,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0643,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0559, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0881,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0063,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1394,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0210,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0177,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0783,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0936, -0.0063, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0667, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1347, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0256,  0.0107, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0818,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1118,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1244, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0254,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0904,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0255,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1249,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0495,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1120, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0205,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1396, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0489, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0234,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0546,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1384, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "After backwards\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0287,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0026, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0009, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0002, -0.0024,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0069, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0031, -0.0016, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0013, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0442,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0643,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0559, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0881,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0063,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1394,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0210,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0177,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0783,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0936, -0.0063, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0667, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1347, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0256,  0.0107, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0818,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1118,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1244, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0254,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0904,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0255,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1249,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0495,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1120, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0205,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1396, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0489, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0234,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0546,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0609e-03, -9.5343e-04, -1.2445e-03, -3.9385e-03, -1.0681e-04,\n",
      "          3.4440e-03, -5.3210e-04,  2.9400e-04,  4.8728e-03, -7.8152e-03,\n",
      "         -2.8975e-03,  1.7599e-03,  1.5046e-03,  7.8342e-04,  1.7767e-03,\n",
      "         -9.3063e-03,  3.2110e-03, -7.3381e-03,  1.6759e-03,  9.8755e-04,\n",
      "         -1.1533e-02,  1.6824e-03,  3.7916e-03, -3.9957e-03,  9.8164e-04,\n",
      "         -1.1293e-04, -6.2490e-05,  7.8710e-03,  1.5045e-03, -5.0477e-03,\n",
      "         -1.6748e-02,  1.2218e-04, -3.8563e-03, -1.2420e-02, -4.1173e-03,\n",
      "         -8.2323e-03,  4.3494e-03, -6.4964e-03,  1.9098e-03, -1.2023e-02,\n",
      "          5.5364e-03,  2.8389e-03,  1.7543e-03, -6.9238e-03,  6.1389e-03,\n",
      "          3.7639e-03, -1.2411e-02,  2.3708e-05,  2.5456e-03, -2.1799e-03],\n",
      "        [ 3.4544e-03, -2.2815e-03,  1.0189e-03,  4.4352e-03,  3.4155e-03,\n",
      "         -2.9647e-04, -4.5214e-03, -2.5995e-03, -5.3879e-03,  4.0892e-03,\n",
      "          2.7866e-03, -5.8800e-03,  4.3732e-03, -7.5685e-03, -1.4282e-03,\n",
      "         -9.9404e-04, -5.5116e-03,  3.9863e-03, -3.7812e-03, -7.8223e-03,\n",
      "          1.0610e-02, -1.3030e-03, -8.0809e-03,  1.9923e-03,  2.2792e-03,\n",
      "          2.3244e-03,  1.8775e-03, -1.4368e-02,  1.3889e-03,  6.3373e-03,\n",
      "          1.4544e-02,  1.1259e-03,  8.8504e-03,  9.5144e-03,  1.9108e-03,\n",
      "          3.1552e-03, -1.1632e-03,  7.3470e-03,  6.6663e-03,  8.1857e-03,\n",
      "         -3.8501e-03,  7.6628e-03,  5.6797e-05,  4.6082e-03, -6.9491e-03,\n",
      "         -4.3752e-03,  7.4647e-04, -2.5317e-03,  6.3914e-03,  1.2894e-03],\n",
      "        [ 1.8748e-03,  2.6607e-03, -1.3538e-05,  3.3628e-03, -4.5823e-03,\n",
      "         -2.3477e-04, -2.1184e-03,  8.6844e-04,  3.7496e-03, -7.7351e-03,\n",
      "          1.7301e-03,  2.1195e-03, -1.0969e-03,  6.0652e-04, -1.0389e-04,\n",
      "         -5.2536e-03,  4.6023e-04,  1.9963e-03,  3.2196e-03, -3.3604e-03,\n",
      "         -3.3260e-03, -2.7819e-04,  2.4974e-03,  9.6821e-04,  3.5298e-04,\n",
      "         -2.7864e-03,  2.0726e-04, -1.2501e-03, -4.0563e-03,  3.4073e-03,\n",
      "         -1.9693e-03, -1.7508e-03, -3.6126e-03, -6.6386e-03,  1.3593e-03,\n",
      "          2.0776e-03, -3.7149e-04, -1.2833e-02, -1.0261e-03,  7.7745e-04,\n",
      "         -2.5355e-03,  1.5462e-03, -4.3261e-03,  1.8942e-03,  1.1256e-04,\n",
      "          2.9285e-03,  7.3384e-03,  1.3386e-03, -3.6526e-03, -3.3953e-04],\n",
      "        [ 1.0852e-03,  6.1686e-03, -3.9000e-04, -8.6714e-03,  7.4885e-04,\n",
      "         -3.0418e-03, -3.8046e-03, -3.0257e-04,  4.8406e-03,  1.9041e-03,\n",
      "          1.4405e-03,  2.4464e-03, -1.8769e-02,  2.3854e-03, -3.8776e-03,\n",
      "         -1.8799e-03, -2.2636e-03, -1.2308e-03, -2.0648e-03,  1.5524e-03,\n",
      "         -3.4413e-03, -1.5058e-03,  3.4027e-03,  1.1604e-03, -5.2691e-04,\n",
      "         -3.4831e-03, -8.5455e-04,  2.0163e-03,  5.6798e-04, -7.3910e-03,\n",
      "          6.1945e-03,  9.4858e-04, -1.4608e-02, -1.5007e-03, -2.2170e-04,\n",
      "         -1.6657e-03,  2.5482e-03,  4.9942e-04, -1.2665e-03,  7.7474e-03,\n",
      "         -2.0657e-03,  3.2250e-04, -6.2208e-03,  2.4537e-03,  2.6162e-03,\n",
      "         -4.8094e-03, -1.4119e-03, -5.6826e-04, -1.9657e-03,  9.9165e-04],\n",
      "        [-1.8609e-03,  2.8286e-03,  4.6898e-04,  1.9419e-03, -3.1472e-03,\n",
      "         -3.8578e-03,  5.0533e-03,  6.2930e-04,  8.3847e-04,  1.4297e-03,\n",
      "          1.8481e-03,  3.6246e-03,  3.3578e-03,  5.7781e-03,  7.2003e-04,\n",
      "          1.1099e-02, -1.0300e-03,  5.7336e-04,  1.2099e-03,  2.4563e-03,\n",
      "         -2.3854e-03,  8.9704e-04, -1.4125e-03,  1.1278e-03,  9.7556e-04,\n",
      "         -8.7238e-04, -1.2855e-03,  1.6626e-03, -2.2183e-04, -1.4383e-03,\n",
      "         -1.6364e-03,  5.9246e-04,  1.0318e-02, -1.4350e-03, -3.3907e-05,\n",
      "          2.0982e-03, -2.9913e-03,  1.1820e-03, -5.6213e-03, -1.8189e-03,\n",
      "         -3.1193e-04, -4.5785e-03,  2.5245e-03, -2.3729e-03, -3.7970e-04,\n",
      "         -3.0894e-03,  1.1036e-02,  1.3349e-03,  2.2391e-03,  2.1530e-05],\n",
      "        [ 3.0923e-03, -1.3830e-03, -6.6226e-05, -6.5308e-04, -5.6521e-04,\n",
      "         -1.0691e-03, -2.0471e-03, -3.1653e-04, -9.5970e-04,  1.1685e-03,\n",
      "          1.0976e-03, -2.8431e-03, -1.7971e-03, -1.6414e-03, -2.8408e-04,\n",
      "          2.8559e-03,  2.0539e-03, -2.9917e-04, -3.0494e-03,  1.0470e-03,\n",
      "          2.0132e-03,  7.5862e-04, -2.5206e-03, -2.7964e-03,  1.0414e-03,\n",
      "          1.2844e-03, -2.1276e-03,  2.9999e-03,  4.5962e-04, -4.2992e-03,\n",
      "         -4.1370e-03, -2.1676e-04, -7.4322e-03,  6.8884e-04, -8.5088e-04,\n",
      "         -2.9729e-03,  5.6802e-04,  2.7875e-03, -2.2035e-03,  5.9324e-03,\n",
      "         -7.1649e-04,  2.5842e-03,  3.1322e-04, -8.3008e-04,  5.6073e-03,\n",
      "          2.0805e-04, -1.0988e-02, -1.0722e-04,  1.8311e-03,  3.0388e-04],\n",
      "        [ 2.2750e-03, -2.9853e-03,  7.2421e-04,  4.4805e-03, -1.3911e-03,\n",
      "          2.4071e-03, -5.8367e-04,  1.3877e-03, -1.4897e-04,  3.2444e-03,\n",
      "          4.4367e-03, -4.0574e-04,  7.7423e-03, -1.9661e-03,  5.3279e-04,\n",
      "         -3.2044e-03,  6.6929e-04, -1.4014e-03,  4.7758e-04,  2.1534e-03,\n",
      "         -2.6104e-03,  1.3869e-03,  2.3524e-03,  2.0630e-04, -6.4897e-03,\n",
      "          1.8022e-03,  1.0032e-03, -1.1821e-04,  2.4199e-04,  5.1995e-03,\n",
      "          5.0858e-03, -2.0836e-03, -7.2018e-03, -6.1772e-04, -1.2018e-03,\n",
      "          2.8020e-03, -3.3145e-03, -5.8560e-03, -1.3589e-03, -1.1179e-02,\n",
      "          2.4425e-03,  5.3718e-03, -4.4613e-03,  1.7892e-03,  6.1445e-03,\n",
      "          6.8515e-03, -1.9070e-03,  2.2958e-03,  4.3775e-03, -9.8374e-04],\n",
      "        [-6.4360e-03, -1.9212e-03, -1.9824e-03, -7.4725e-05,  4.2392e-03,\n",
      "          2.0661e-03,  3.4743e-03,  5.2971e-04, -4.5933e-03,  2.3470e-03,\n",
      "         -7.4047e-03, -3.6400e-03, -1.0889e-03,  1.7969e-03,  1.2416e-03,\n",
      "          2.1959e-04, -1.6322e-05, -1.0362e-03,  3.2625e-05, -1.1383e-04,\n",
      "          6.5857e-03, -2.2208e-03, -7.1517e-04, -1.2629e-04, -1.5996e-03,\n",
      "          2.8605e-04,  1.1801e-03,  1.3128e-03,  3.4013e-04,  5.2289e-03,\n",
      "         -9.2818e-04,  3.7210e-04,  1.3860e-02,  3.4020e-03,  1.0211e-03,\n",
      "          8.0687e-04,  1.4882e-04,  2.5518e-03,  4.2659e-03, -1.3415e-03,\n",
      "          1.6043e-03, -9.2529e-03,  5.2866e-03, -2.2069e-03, -6.6691e-03,\n",
      "          3.6947e-03,  5.5924e-03,  2.9861e-04, -3.5245e-03,  3.4947e-04],\n",
      "        [-2.6274e-03, -1.2573e-03,  7.5194e-04, -3.0540e-04, -1.1362e-03,\n",
      "         -8.5681e-04,  1.3358e-03, -9.4539e-04,  4.7784e-04, -4.3093e-03,\n",
      "          9.7008e-04,  1.5709e-03,  1.1074e-03, -3.1172e-03, -1.0910e-04,\n",
      "         -2.4833e-03, -6.3362e-04,  3.0246e-03,  2.5240e-03,  4.5494e-04,\n",
      "         -2.8919e-03, -4.8518e-04, -5.3803e-04,  1.9867e-04,  1.2531e-03,\n",
      "          1.6246e-03,  3.7304e-04, -2.4369e-03, -5.4148e-04, -3.0628e-03,\n",
      "         -4.6176e-04,  8.6697e-05, -5.8380e-03,  3.6437e-03,  1.4843e-03,\n",
      "          1.0783e-03,  1.5554e-03,  4.4634e-03, -4.0339e-03,  3.6252e-03,\n",
      "          8.1443e-04,  6.4442e-04, -1.4112e-04,  7.1587e-04, -3.8819e-03,\n",
      "         -1.0331e-02, -6.7483e-03, -2.9509e-04, -8.1970e-03,  6.3334e-04],\n",
      "        [-4.9182e-03, -8.7617e-04,  7.3265e-04, -5.7733e-04,  2.5253e-03,\n",
      "          1.4395e-03,  3.7439e-03,  4.5486e-04, -3.6895e-03,  5.6766e-03,\n",
      "         -4.0076e-03,  1.2477e-03,  4.6669e-03,  2.9429e-03,  1.5318e-03,\n",
      "          8.9470e-03,  3.0606e-03,  1.7251e-03, -2.4431e-04,  2.6449e-03,\n",
      "          6.9783e-03,  1.0680e-03,  1.2231e-03,  1.2647e-03,  1.7324e-03,\n",
      "         -6.6935e-05, -3.1105e-04,  2.3106e-03,  3.1657e-04,  1.0660e-03,\n",
      "          5.6916e-05,  8.0324e-04,  9.5206e-03,  5.3627e-03,  6.4998e-04,\n",
      "          8.5268e-04, -1.3295e-03,  6.3546e-03,  2.6680e-03,  9.4371e-05,\n",
      "         -9.1786e-04, -7.1395e-03,  5.2139e-03,  8.7246e-04, -2.7396e-03,\n",
      "          5.1583e-03,  8.7535e-03, -1.7894e-03, -4.4769e-05, -8.6056e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1384, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0027, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "After optimization step\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0026, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0009, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0002, -0.0024,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0069, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0031, -0.0016, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0013, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0442,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0559, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0881,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1394,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0210,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0177,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0783,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0667, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1118,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1244, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0254,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0904,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0255,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1249,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0495,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1396, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0234,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0609e-03, -9.5343e-04, -1.2445e-03, -3.9385e-03, -1.0681e-04,\n",
      "          3.4440e-03, -5.3210e-04,  2.9400e-04,  4.8728e-03, -7.8152e-03,\n",
      "         -2.8975e-03,  1.7599e-03,  1.5046e-03,  7.8342e-04,  1.7767e-03,\n",
      "         -9.3063e-03,  3.2110e-03, -7.3381e-03,  1.6759e-03,  9.8755e-04,\n",
      "         -1.1533e-02,  1.6824e-03,  3.7916e-03, -3.9957e-03,  9.8164e-04,\n",
      "         -1.1293e-04, -6.2490e-05,  7.8710e-03,  1.5045e-03, -5.0477e-03,\n",
      "         -1.6748e-02,  1.2218e-04, -3.8563e-03, -1.2420e-02, -4.1173e-03,\n",
      "         -8.2323e-03,  4.3494e-03, -6.4964e-03,  1.9098e-03, -1.2023e-02,\n",
      "          5.5364e-03,  2.8389e-03,  1.7543e-03, -6.9238e-03,  6.1389e-03,\n",
      "          3.7639e-03, -1.2411e-02,  2.3708e-05,  2.5456e-03, -2.1799e-03],\n",
      "        [ 3.4544e-03, -2.2815e-03,  1.0189e-03,  4.4352e-03,  3.4155e-03,\n",
      "         -2.9647e-04, -4.5214e-03, -2.5995e-03, -5.3879e-03,  4.0892e-03,\n",
      "          2.7866e-03, -5.8800e-03,  4.3732e-03, -7.5685e-03, -1.4282e-03,\n",
      "         -9.9404e-04, -5.5116e-03,  3.9863e-03, -3.7812e-03, -7.8223e-03,\n",
      "          1.0610e-02, -1.3030e-03, -8.0809e-03,  1.9923e-03,  2.2792e-03,\n",
      "          2.3244e-03,  1.8775e-03, -1.4368e-02,  1.3889e-03,  6.3373e-03,\n",
      "          1.4544e-02,  1.1259e-03,  8.8504e-03,  9.5144e-03,  1.9108e-03,\n",
      "          3.1552e-03, -1.1632e-03,  7.3470e-03,  6.6663e-03,  8.1857e-03,\n",
      "         -3.8501e-03,  7.6628e-03,  5.6797e-05,  4.6082e-03, -6.9491e-03,\n",
      "         -4.3752e-03,  7.4647e-04, -2.5317e-03,  6.3914e-03,  1.2894e-03],\n",
      "        [ 1.8748e-03,  2.6607e-03, -1.3538e-05,  3.3628e-03, -4.5823e-03,\n",
      "         -2.3477e-04, -2.1184e-03,  8.6844e-04,  3.7496e-03, -7.7351e-03,\n",
      "          1.7301e-03,  2.1195e-03, -1.0969e-03,  6.0652e-04, -1.0389e-04,\n",
      "         -5.2536e-03,  4.6023e-04,  1.9963e-03,  3.2196e-03, -3.3604e-03,\n",
      "         -3.3260e-03, -2.7819e-04,  2.4974e-03,  9.6821e-04,  3.5298e-04,\n",
      "         -2.7864e-03,  2.0726e-04, -1.2501e-03, -4.0563e-03,  3.4073e-03,\n",
      "         -1.9693e-03, -1.7508e-03, -3.6126e-03, -6.6386e-03,  1.3593e-03,\n",
      "          2.0776e-03, -3.7149e-04, -1.2833e-02, -1.0261e-03,  7.7745e-04,\n",
      "         -2.5355e-03,  1.5462e-03, -4.3261e-03,  1.8942e-03,  1.1256e-04,\n",
      "          2.9285e-03,  7.3384e-03,  1.3386e-03, -3.6526e-03, -3.3953e-04],\n",
      "        [ 1.0852e-03,  6.1686e-03, -3.9000e-04, -8.6714e-03,  7.4885e-04,\n",
      "         -3.0418e-03, -3.8046e-03, -3.0257e-04,  4.8406e-03,  1.9041e-03,\n",
      "          1.4405e-03,  2.4464e-03, -1.8769e-02,  2.3854e-03, -3.8776e-03,\n",
      "         -1.8799e-03, -2.2636e-03, -1.2308e-03, -2.0648e-03,  1.5524e-03,\n",
      "         -3.4413e-03, -1.5058e-03,  3.4027e-03,  1.1604e-03, -5.2691e-04,\n",
      "         -3.4831e-03, -8.5455e-04,  2.0163e-03,  5.6798e-04, -7.3910e-03,\n",
      "          6.1945e-03,  9.4858e-04, -1.4608e-02, -1.5007e-03, -2.2170e-04,\n",
      "         -1.6657e-03,  2.5482e-03,  4.9942e-04, -1.2665e-03,  7.7474e-03,\n",
      "         -2.0657e-03,  3.2250e-04, -6.2208e-03,  2.4537e-03,  2.6162e-03,\n",
      "         -4.8094e-03, -1.4119e-03, -5.6826e-04, -1.9657e-03,  9.9165e-04],\n",
      "        [-1.8609e-03,  2.8286e-03,  4.6898e-04,  1.9419e-03, -3.1472e-03,\n",
      "         -3.8578e-03,  5.0533e-03,  6.2930e-04,  8.3847e-04,  1.4297e-03,\n",
      "          1.8481e-03,  3.6246e-03,  3.3578e-03,  5.7781e-03,  7.2003e-04,\n",
      "          1.1099e-02, -1.0300e-03,  5.7336e-04,  1.2099e-03,  2.4563e-03,\n",
      "         -2.3854e-03,  8.9704e-04, -1.4125e-03,  1.1278e-03,  9.7556e-04,\n",
      "         -8.7238e-04, -1.2855e-03,  1.6626e-03, -2.2183e-04, -1.4383e-03,\n",
      "         -1.6364e-03,  5.9246e-04,  1.0318e-02, -1.4350e-03, -3.3907e-05,\n",
      "          2.0982e-03, -2.9913e-03,  1.1820e-03, -5.6213e-03, -1.8189e-03,\n",
      "         -3.1193e-04, -4.5785e-03,  2.5245e-03, -2.3729e-03, -3.7970e-04,\n",
      "         -3.0894e-03,  1.1036e-02,  1.3349e-03,  2.2391e-03,  2.1530e-05],\n",
      "        [ 3.0923e-03, -1.3830e-03, -6.6226e-05, -6.5308e-04, -5.6521e-04,\n",
      "         -1.0691e-03, -2.0471e-03, -3.1653e-04, -9.5970e-04,  1.1685e-03,\n",
      "          1.0976e-03, -2.8431e-03, -1.7971e-03, -1.6414e-03, -2.8408e-04,\n",
      "          2.8559e-03,  2.0539e-03, -2.9917e-04, -3.0494e-03,  1.0470e-03,\n",
      "          2.0132e-03,  7.5862e-04, -2.5206e-03, -2.7964e-03,  1.0414e-03,\n",
      "          1.2844e-03, -2.1276e-03,  2.9999e-03,  4.5962e-04, -4.2992e-03,\n",
      "         -4.1370e-03, -2.1676e-04, -7.4322e-03,  6.8884e-04, -8.5088e-04,\n",
      "         -2.9729e-03,  5.6802e-04,  2.7875e-03, -2.2035e-03,  5.9324e-03,\n",
      "         -7.1649e-04,  2.5842e-03,  3.1322e-04, -8.3008e-04,  5.6073e-03,\n",
      "          2.0805e-04, -1.0988e-02, -1.0722e-04,  1.8311e-03,  3.0388e-04],\n",
      "        [ 2.2750e-03, -2.9853e-03,  7.2421e-04,  4.4805e-03, -1.3911e-03,\n",
      "          2.4071e-03, -5.8367e-04,  1.3877e-03, -1.4897e-04,  3.2444e-03,\n",
      "          4.4367e-03, -4.0574e-04,  7.7423e-03, -1.9661e-03,  5.3279e-04,\n",
      "         -3.2044e-03,  6.6929e-04, -1.4014e-03,  4.7758e-04,  2.1534e-03,\n",
      "         -2.6104e-03,  1.3869e-03,  2.3524e-03,  2.0630e-04, -6.4897e-03,\n",
      "          1.8022e-03,  1.0032e-03, -1.1821e-04,  2.4199e-04,  5.1995e-03,\n",
      "          5.0858e-03, -2.0836e-03, -7.2018e-03, -6.1772e-04, -1.2018e-03,\n",
      "          2.8020e-03, -3.3145e-03, -5.8560e-03, -1.3589e-03, -1.1179e-02,\n",
      "          2.4425e-03,  5.3718e-03, -4.4613e-03,  1.7892e-03,  6.1445e-03,\n",
      "          6.8515e-03, -1.9070e-03,  2.2958e-03,  4.3775e-03, -9.8374e-04],\n",
      "        [-6.4360e-03, -1.9212e-03, -1.9824e-03, -7.4725e-05,  4.2392e-03,\n",
      "          2.0661e-03,  3.4743e-03,  5.2971e-04, -4.5933e-03,  2.3470e-03,\n",
      "         -7.4047e-03, -3.6400e-03, -1.0889e-03,  1.7969e-03,  1.2416e-03,\n",
      "          2.1959e-04, -1.6322e-05, -1.0362e-03,  3.2625e-05, -1.1383e-04,\n",
      "          6.5857e-03, -2.2208e-03, -7.1517e-04, -1.2629e-04, -1.5996e-03,\n",
      "          2.8605e-04,  1.1801e-03,  1.3128e-03,  3.4013e-04,  5.2289e-03,\n",
      "         -9.2818e-04,  3.7210e-04,  1.3860e-02,  3.4020e-03,  1.0211e-03,\n",
      "          8.0687e-04,  1.4882e-04,  2.5518e-03,  4.2659e-03, -1.3415e-03,\n",
      "          1.6043e-03, -9.2529e-03,  5.2866e-03, -2.2069e-03, -6.6691e-03,\n",
      "          3.6947e-03,  5.5924e-03,  2.9861e-04, -3.5245e-03,  3.4947e-04],\n",
      "        [-2.6274e-03, -1.2573e-03,  7.5194e-04, -3.0540e-04, -1.1362e-03,\n",
      "         -8.5681e-04,  1.3358e-03, -9.4539e-04,  4.7784e-04, -4.3093e-03,\n",
      "          9.7008e-04,  1.5709e-03,  1.1074e-03, -3.1172e-03, -1.0910e-04,\n",
      "         -2.4833e-03, -6.3362e-04,  3.0246e-03,  2.5240e-03,  4.5494e-04,\n",
      "         -2.8919e-03, -4.8518e-04, -5.3803e-04,  1.9867e-04,  1.2531e-03,\n",
      "          1.6246e-03,  3.7304e-04, -2.4369e-03, -5.4148e-04, -3.0628e-03,\n",
      "         -4.6176e-04,  8.6697e-05, -5.8380e-03,  3.6437e-03,  1.4843e-03,\n",
      "          1.0783e-03,  1.5554e-03,  4.4634e-03, -4.0339e-03,  3.6252e-03,\n",
      "          8.1443e-04,  6.4442e-04, -1.4112e-04,  7.1587e-04, -3.8819e-03,\n",
      "         -1.0331e-02, -6.7483e-03, -2.9509e-04, -8.1970e-03,  6.3334e-04],\n",
      "        [-4.9182e-03, -8.7617e-04,  7.3265e-04, -5.7733e-04,  2.5253e-03,\n",
      "          1.4395e-03,  3.7439e-03,  4.5486e-04, -3.6895e-03,  5.6766e-03,\n",
      "         -4.0076e-03,  1.2477e-03,  4.6669e-03,  2.9429e-03,  1.5318e-03,\n",
      "          8.9470e-03,  3.0606e-03,  1.7251e-03, -2.4431e-04,  2.6449e-03,\n",
      "          6.9783e-03,  1.0680e-03,  1.2231e-03,  1.2647e-03,  1.7324e-03,\n",
      "         -6.6935e-05, -3.1105e-04,  2.3106e-03,  3.1657e-04,  1.0660e-03,\n",
      "          5.6916e-05,  8.0324e-04,  9.5206e-03,  5.3627e-03,  6.4998e-04,\n",
      "          8.5268e-04, -1.3295e-03,  6.3546e-03,  2.6680e-03,  9.4371e-05,\n",
      "         -9.1786e-04, -7.1395e-03,  5.2139e-03,  8.7246e-04, -2.7396e-03,\n",
      "          5.1583e-03,  8.7535e-03, -1.7894e-03, -4.4769e-05, -8.6056e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1384, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0027, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "Epoch: 0 done. Test loss 2.3034965991973877. Test accuracy 0.1039\n",
      "Loss:  tensor(2.3028, grad_fn=<DivBackward1>)\n",
      "After zero grad\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0026, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0442,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0559, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0881,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1394,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0210,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0177,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0783,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0667, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1118,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1244, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0254,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0904,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0255,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1249,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0495,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1396, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0234,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1384, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "After backwards\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0026, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0008, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0001, -0.0025,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0069, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0032, -0.0016, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0013, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0442,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0559, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0881,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1394,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0210,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0177,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0783,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0667, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1118,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1244, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0254,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0904,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0255,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1249,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0495,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1396, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0234,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0625e-03, -9.0844e-04, -1.2442e-03, -3.9556e-03, -9.8432e-05,\n",
      "          3.4419e-03, -5.5016e-04,  2.9496e-04,  4.8668e-03, -7.8284e-03,\n",
      "         -2.8825e-03,  1.7393e-03,  1.5027e-03,  7.9156e-04,  1.7803e-03,\n",
      "         -9.2870e-03,  3.2042e-03, -7.3116e-03,  1.6747e-03,  9.8628e-04,\n",
      "         -1.1568e-02,  1.6883e-03,  3.7927e-03, -3.9912e-03,  9.8013e-04,\n",
      "         -1.0895e-04, -5.9961e-05,  7.8750e-03,  1.5044e-03, -5.0475e-03,\n",
      "         -1.6735e-02,  1.2227e-04, -3.8381e-03, -1.2383e-02, -4.1332e-03,\n",
      "         -8.2338e-03,  4.3458e-03, -6.4870e-03,  1.9071e-03, -1.2004e-02,\n",
      "          5.5391e-03,  2.8390e-03,  1.7601e-03, -6.9399e-03,  6.1388e-03,\n",
      "          3.7530e-03, -1.2414e-02,  1.8644e-05,  2.5446e-03, -2.1799e-03],\n",
      "        [ 3.4535e-03, -2.3166e-03,  1.0188e-03,  4.4502e-03,  3.4142e-03,\n",
      "         -3.0442e-04, -4.5072e-03, -2.5981e-03, -5.3839e-03,  4.0945e-03,\n",
      "          2.7807e-03, -5.8534e-03,  4.3790e-03, -7.5656e-03, -1.4326e-03,\n",
      "         -1.0054e-03, -5.4985e-03,  3.9717e-03, -3.7749e-03, -7.8255e-03,\n",
      "          1.0632e-02, -1.3076e-03, -8.0829e-03,  1.9897e-03,  2.2856e-03,\n",
      "          2.3150e-03,  1.8709e-03, -1.4379e-02,  1.3881e-03,  6.3421e-03,\n",
      "          1.4550e-02,  1.1264e-03,  8.8651e-03,  9.4908e-03,  1.9175e-03,\n",
      "          3.1567e-03, -1.1723e-03,  7.3392e-03,  6.6630e-03,  8.1667e-03,\n",
      "         -3.8621e-03,  7.6632e-03,  4.6104e-05,  4.6122e-03, -6.9348e-03,\n",
      "         -4.3669e-03,  7.4548e-04, -2.5287e-03,  6.3955e-03,  1.2893e-03],\n",
      "        [ 1.8756e-03,  2.6514e-03, -1.3596e-05,  3.3677e-03, -4.5838e-03,\n",
      "         -2.3764e-04, -2.1221e-03,  8.6765e-04,  3.7443e-03, -7.7328e-03,\n",
      "          1.7316e-03,  2.1299e-03, -1.0922e-03,  6.1370e-04, -1.0397e-04,\n",
      "         -5.2529e-03,  4.6901e-04,  1.9907e-03,  3.2196e-03, -3.3653e-03,\n",
      "         -3.3328e-03, -2.7787e-04,  2.4963e-03,  9.6761e-04,  3.5385e-04,\n",
      "         -2.7784e-03,  2.0578e-04, -1.2589e-03, -4.0579e-03,  3.4068e-03,\n",
      "         -1.9796e-03, -1.7521e-03, -3.5994e-03, -6.6333e-03,  1.3646e-03,\n",
      "          2.0792e-03, -3.7421e-04, -1.2836e-02, -1.0285e-03,  7.8337e-04,\n",
      "         -2.5284e-03,  1.5481e-03, -4.3123e-03,  1.8955e-03,  1.1756e-04,\n",
      "          2.9301e-03,  7.3444e-03,  1.3386e-03, -3.6558e-03, -3.3978e-04],\n",
      "        [ 1.0883e-03,  6.1675e-03, -3.8985e-04, -8.6735e-03,  7.4705e-04,\n",
      "         -3.0365e-03, -3.8165e-03, -3.0213e-04,  4.8355e-03,  1.9045e-03,\n",
      "          1.4415e-03,  2.4555e-03, -1.8769e-02,  2.3874e-03, -3.8835e-03,\n",
      "         -1.8764e-03, -2.2704e-03, -1.2269e-03, -2.0658e-03,  1.5526e-03,\n",
      "         -3.4431e-03, -1.5110e-03,  3.4050e-03,  1.1606e-03, -5.2544e-04,\n",
      "         -3.4705e-03, -8.4862e-04,  2.0181e-03,  5.6802e-04, -7.4046e-03,\n",
      "          6.2012e-03,  9.4924e-04, -1.4593e-02, -1.4949e-03, -2.2066e-04,\n",
      "         -1.6704e-03,  2.5430e-03,  4.9582e-04, -1.2752e-03,  7.7402e-03,\n",
      "         -2.0679e-03,  3.2373e-04, -6.2009e-03,  2.4551e-03,  2.6185e-03,\n",
      "         -4.8210e-03, -1.4004e-03, -5.7013e-04, -1.9750e-03,  9.9207e-04],\n",
      "        [-1.8628e-03,  2.8253e-03,  4.6895e-04,  1.9416e-03, -3.1517e-03,\n",
      "         -3.8533e-03,  5.0621e-03,  6.2836e-04,  8.3900e-04,  1.4309e-03,\n",
      "          1.8484e-03,  3.6170e-03,  3.3577e-03,  5.7627e-03,  7.2156e-04,\n",
      "          1.1094e-02, -1.0323e-03,  5.7183e-04,  1.2088e-03,  2.4590e-03,\n",
      "         -2.3838e-03,  9.0017e-04, -1.4141e-03,  1.1255e-03,  9.7355e-04,\n",
      "         -8.7241e-04, -1.2852e-03,  1.6698e-03, -2.2144e-04, -1.4379e-03,\n",
      "         -1.6520e-03,  5.9288e-04,  1.0298e-02, -1.4419e-03, -3.3174e-05,\n",
      "          2.0998e-03, -2.9827e-03,  1.1811e-03, -5.6095e-03, -1.8168e-03,\n",
      "         -3.0984e-04, -4.5773e-03,  2.5142e-03, -2.3695e-03, -3.9110e-04,\n",
      "         -3.0831e-03,  1.1035e-02,  1.3356e-03,  2.2436e-03,  2.1632e-05],\n",
      "        [ 3.0927e-03, -1.3735e-03, -6.6347e-05, -6.5605e-04, -5.6323e-04,\n",
      "         -1.0659e-03, -2.0511e-03, -3.1620e-04, -9.6148e-04,  1.1675e-03,\n",
      "          1.0990e-03, -2.8502e-03, -1.7973e-03, -1.6359e-03, -2.8377e-04,\n",
      "          2.8571e-03,  2.0497e-03, -2.9983e-04, -3.0506e-03,  1.0469e-03,\n",
      "          2.0153e-03,  7.6010e-04, -2.5183e-03, -2.7928e-03,  1.0419e-03,\n",
      "          1.2814e-03, -2.1203e-03,  3.0026e-03,  4.6001e-04, -4.3039e-03,\n",
      "         -4.1321e-03, -2.1677e-04, -7.4321e-03,  6.9175e-04, -8.5496e-04,\n",
      "         -2.9756e-03,  5.6714e-04,  2.7899e-03, -2.2092e-03,  5.9277e-03,\n",
      "         -7.1565e-04,  2.5847e-03,  3.1482e-04, -8.3131e-04,  5.6032e-03,\n",
      "          2.0471e-04, -1.0986e-02, -1.0855e-04,  1.8293e-03,  3.0409e-04],\n",
      "        [ 2.2723e-03, -2.9917e-03,  7.2421e-04,  4.4806e-03, -1.3914e-03,\n",
      "          2.4033e-03, -5.8650e-04,  1.3862e-03, -1.5524e-04,  3.2476e-03,\n",
      "          4.4397e-03, -4.1201e-04,  7.7491e-03, -1.9652e-03,  5.3335e-04,\n",
      "         -3.2145e-03,  6.7595e-04, -1.3964e-03,  4.8186e-04,  2.1550e-03,\n",
      "         -2.6113e-03,  1.3915e-03,  2.3524e-03,  2.0393e-04, -6.5066e-03,\n",
      "          1.7986e-03,  1.0002e-03, -1.2524e-04,  2.4118e-04,  5.2004e-03,\n",
      "          5.0727e-03, -2.0845e-03, -7.2142e-03, -6.2673e-04, -1.2068e-03,\n",
      "          2.8038e-03, -3.3053e-03, -5.8458e-03, -1.3588e-03, -1.1163e-02,\n",
      "          2.4458e-03,  5.3727e-03, -4.4535e-03,  1.7895e-03,  6.1375e-03,\n",
      "          6.8618e-03, -1.9009e-03,  2.2964e-03,  4.3752e-03, -9.8428e-04],\n",
      "        [-6.4355e-03, -1.9155e-03, -1.9827e-03, -7.4858e-05,  4.2387e-03,\n",
      "          2.0654e-03,  3.4809e-03,  5.2885e-04, -4.5808e-03,  2.3467e-03,\n",
      "         -7.4133e-03, -3.6432e-03, -1.1011e-03,  1.7849e-03,  1.2436e-03,\n",
      "          2.1718e-04, -2.4752e-05, -1.0338e-03,  2.8605e-05, -1.1141e-04,\n",
      "          6.5957e-03, -2.2248e-03, -7.1939e-04, -1.2582e-04, -1.5933e-03,\n",
      "          2.8413e-04,  1.1755e-03,  1.3185e-03,  3.4048e-04,  5.2416e-03,\n",
      "         -9.2178e-04,  3.7221e-04,  1.3847e-02,  3.4035e-03,  1.0252e-03,\n",
      "          8.0758e-04,  1.5134e-04,  2.5465e-03,  4.2728e-03, -1.3472e-03,\n",
      "          1.6038e-03, -9.2578e-03,  5.2702e-03, -2.2036e-03, -6.6720e-03,\n",
      "          3.6992e-03,  5.5809e-03,  2.9969e-04, -3.5200e-03,  3.4954e-04],\n",
      "        [-2.6273e-03, -1.2638e-03,  7.5205e-04, -3.0412e-04, -1.1347e-03,\n",
      "         -8.5461e-04,  1.3379e-03, -9.4398e-04,  4.7771e-04, -4.3105e-03,\n",
      "          9.6870e-04,  1.5752e-03,  1.1075e-03, -3.1053e-03, -1.0905e-04,\n",
      "         -2.4785e-03, -6.2771e-04,  3.0151e-03,  2.5240e-03,  4.5444e-04,\n",
      "         -2.8922e-03, -4.8959e-04, -5.3485e-04,  1.9947e-04,  1.2557e-03,\n",
      "          1.6207e-03,  3.7375e-04, -2.4393e-03, -5.4010e-04, -3.0701e-03,\n",
      "         -4.5853e-04,  8.6582e-05, -5.8335e-03,  3.6405e-03,  1.4892e-03,\n",
      "          1.0787e-03,  1.5522e-03,  4.4634e-03, -4.0373e-03,  3.6216e-03,\n",
      "          8.1371e-04,  6.4314e-04, -1.3688e-04,  7.1605e-04, -3.8697e-03,\n",
      "         -1.0341e-02, -6.7525e-03, -2.9437e-04, -8.1970e-03,  6.3331e-04],\n",
      "        [-4.9193e-03, -8.7471e-04,  7.3275e-04, -5.7591e-04,  2.5233e-03,\n",
      "          1.4417e-03,  3.7526e-03,  4.5439e-04, -3.6818e-03,  5.6800e-03,\n",
      "         -4.0139e-03,  1.2419e-03,  4.6638e-03,  2.9317e-03,  1.5341e-03,\n",
      "          8.9461e-03,  3.0547e-03,  1.7191e-03, -2.4625e-04,  2.6480e-03,\n",
      "          6.9880e-03,  1.0708e-03,  1.2231e-03,  1.2631e-03,  1.7345e-03,\n",
      "         -6.9656e-05, -3.1202e-04,  2.3185e-03,  3.1728e-04,  1.0730e-03,\n",
      "          5.5470e-05,  8.0373e-04,  9.5001e-03,  5.3537e-03,  6.5227e-04,\n",
      "          8.5402e-04, -1.3250e-03,  6.3525e-03,  2.6757e-03,  9.1293e-05,\n",
      "         -9.1851e-04, -7.1394e-03,  5.1983e-03,  8.7612e-04, -2.7479e-03,\n",
      "          5.1629e-03,  8.7482e-03, -1.7872e-03, -4.0322e-05, -8.5951e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1384, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0026, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "After optimization step\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0025, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0008, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0001, -0.0025,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0069, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0032, -0.0016, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0013, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0441,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0558, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0880,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1395,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0211,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0178,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0784,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0666, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1119,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1245, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0255,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0903,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0254,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1250,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0496,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1397, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0235,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0625e-03, -9.0844e-04, -1.2442e-03, -3.9556e-03, -9.8432e-05,\n",
      "          3.4419e-03, -5.5016e-04,  2.9496e-04,  4.8668e-03, -7.8284e-03,\n",
      "         -2.8825e-03,  1.7393e-03,  1.5027e-03,  7.9156e-04,  1.7803e-03,\n",
      "         -9.2870e-03,  3.2042e-03, -7.3116e-03,  1.6747e-03,  9.8628e-04,\n",
      "         -1.1568e-02,  1.6883e-03,  3.7927e-03, -3.9912e-03,  9.8013e-04,\n",
      "         -1.0895e-04, -5.9961e-05,  7.8750e-03,  1.5044e-03, -5.0475e-03,\n",
      "         -1.6735e-02,  1.2227e-04, -3.8381e-03, -1.2383e-02, -4.1332e-03,\n",
      "         -8.2338e-03,  4.3458e-03, -6.4870e-03,  1.9071e-03, -1.2004e-02,\n",
      "          5.5391e-03,  2.8390e-03,  1.7601e-03, -6.9399e-03,  6.1388e-03,\n",
      "          3.7530e-03, -1.2414e-02,  1.8644e-05,  2.5446e-03, -2.1799e-03],\n",
      "        [ 3.4535e-03, -2.3166e-03,  1.0188e-03,  4.4502e-03,  3.4142e-03,\n",
      "         -3.0442e-04, -4.5072e-03, -2.5981e-03, -5.3839e-03,  4.0945e-03,\n",
      "          2.7807e-03, -5.8534e-03,  4.3790e-03, -7.5656e-03, -1.4326e-03,\n",
      "         -1.0054e-03, -5.4985e-03,  3.9717e-03, -3.7749e-03, -7.8255e-03,\n",
      "          1.0632e-02, -1.3076e-03, -8.0829e-03,  1.9897e-03,  2.2856e-03,\n",
      "          2.3150e-03,  1.8709e-03, -1.4379e-02,  1.3881e-03,  6.3421e-03,\n",
      "          1.4550e-02,  1.1264e-03,  8.8651e-03,  9.4908e-03,  1.9175e-03,\n",
      "          3.1567e-03, -1.1723e-03,  7.3392e-03,  6.6630e-03,  8.1667e-03,\n",
      "         -3.8621e-03,  7.6632e-03,  4.6104e-05,  4.6122e-03, -6.9348e-03,\n",
      "         -4.3669e-03,  7.4548e-04, -2.5287e-03,  6.3955e-03,  1.2893e-03],\n",
      "        [ 1.8756e-03,  2.6514e-03, -1.3596e-05,  3.3677e-03, -4.5838e-03,\n",
      "         -2.3764e-04, -2.1221e-03,  8.6765e-04,  3.7443e-03, -7.7328e-03,\n",
      "          1.7316e-03,  2.1299e-03, -1.0922e-03,  6.1370e-04, -1.0397e-04,\n",
      "         -5.2529e-03,  4.6901e-04,  1.9907e-03,  3.2196e-03, -3.3653e-03,\n",
      "         -3.3328e-03, -2.7787e-04,  2.4963e-03,  9.6761e-04,  3.5385e-04,\n",
      "         -2.7784e-03,  2.0578e-04, -1.2589e-03, -4.0579e-03,  3.4068e-03,\n",
      "         -1.9796e-03, -1.7521e-03, -3.5994e-03, -6.6333e-03,  1.3646e-03,\n",
      "          2.0792e-03, -3.7421e-04, -1.2836e-02, -1.0285e-03,  7.8337e-04,\n",
      "         -2.5284e-03,  1.5481e-03, -4.3123e-03,  1.8955e-03,  1.1756e-04,\n",
      "          2.9301e-03,  7.3444e-03,  1.3386e-03, -3.6558e-03, -3.3978e-04],\n",
      "        [ 1.0883e-03,  6.1675e-03, -3.8985e-04, -8.6735e-03,  7.4705e-04,\n",
      "         -3.0365e-03, -3.8165e-03, -3.0213e-04,  4.8355e-03,  1.9045e-03,\n",
      "          1.4415e-03,  2.4555e-03, -1.8769e-02,  2.3874e-03, -3.8835e-03,\n",
      "         -1.8764e-03, -2.2704e-03, -1.2269e-03, -2.0658e-03,  1.5526e-03,\n",
      "         -3.4431e-03, -1.5110e-03,  3.4050e-03,  1.1606e-03, -5.2544e-04,\n",
      "         -3.4705e-03, -8.4862e-04,  2.0181e-03,  5.6802e-04, -7.4046e-03,\n",
      "          6.2012e-03,  9.4924e-04, -1.4593e-02, -1.4949e-03, -2.2066e-04,\n",
      "         -1.6704e-03,  2.5430e-03,  4.9582e-04, -1.2752e-03,  7.7402e-03,\n",
      "         -2.0679e-03,  3.2373e-04, -6.2009e-03,  2.4551e-03,  2.6185e-03,\n",
      "         -4.8210e-03, -1.4004e-03, -5.7013e-04, -1.9750e-03,  9.9207e-04],\n",
      "        [-1.8628e-03,  2.8253e-03,  4.6895e-04,  1.9416e-03, -3.1517e-03,\n",
      "         -3.8533e-03,  5.0621e-03,  6.2836e-04,  8.3900e-04,  1.4309e-03,\n",
      "          1.8484e-03,  3.6170e-03,  3.3577e-03,  5.7627e-03,  7.2156e-04,\n",
      "          1.1094e-02, -1.0323e-03,  5.7183e-04,  1.2088e-03,  2.4590e-03,\n",
      "         -2.3838e-03,  9.0017e-04, -1.4141e-03,  1.1255e-03,  9.7355e-04,\n",
      "         -8.7241e-04, -1.2852e-03,  1.6698e-03, -2.2144e-04, -1.4379e-03,\n",
      "         -1.6520e-03,  5.9288e-04,  1.0298e-02, -1.4419e-03, -3.3174e-05,\n",
      "          2.0998e-03, -2.9827e-03,  1.1811e-03, -5.6095e-03, -1.8168e-03,\n",
      "         -3.0984e-04, -4.5773e-03,  2.5142e-03, -2.3695e-03, -3.9110e-04,\n",
      "         -3.0831e-03,  1.1035e-02,  1.3356e-03,  2.2436e-03,  2.1632e-05],\n",
      "        [ 3.0927e-03, -1.3735e-03, -6.6347e-05, -6.5605e-04, -5.6323e-04,\n",
      "         -1.0659e-03, -2.0511e-03, -3.1620e-04, -9.6148e-04,  1.1675e-03,\n",
      "          1.0990e-03, -2.8502e-03, -1.7973e-03, -1.6359e-03, -2.8377e-04,\n",
      "          2.8571e-03,  2.0497e-03, -2.9983e-04, -3.0506e-03,  1.0469e-03,\n",
      "          2.0153e-03,  7.6010e-04, -2.5183e-03, -2.7928e-03,  1.0419e-03,\n",
      "          1.2814e-03, -2.1203e-03,  3.0026e-03,  4.6001e-04, -4.3039e-03,\n",
      "         -4.1321e-03, -2.1677e-04, -7.4321e-03,  6.9175e-04, -8.5496e-04,\n",
      "         -2.9756e-03,  5.6714e-04,  2.7899e-03, -2.2092e-03,  5.9277e-03,\n",
      "         -7.1565e-04,  2.5847e-03,  3.1482e-04, -8.3131e-04,  5.6032e-03,\n",
      "          2.0471e-04, -1.0986e-02, -1.0855e-04,  1.8293e-03,  3.0409e-04],\n",
      "        [ 2.2723e-03, -2.9917e-03,  7.2421e-04,  4.4806e-03, -1.3914e-03,\n",
      "          2.4033e-03, -5.8650e-04,  1.3862e-03, -1.5524e-04,  3.2476e-03,\n",
      "          4.4397e-03, -4.1201e-04,  7.7491e-03, -1.9652e-03,  5.3335e-04,\n",
      "         -3.2145e-03,  6.7595e-04, -1.3964e-03,  4.8186e-04,  2.1550e-03,\n",
      "         -2.6113e-03,  1.3915e-03,  2.3524e-03,  2.0393e-04, -6.5066e-03,\n",
      "          1.7986e-03,  1.0002e-03, -1.2524e-04,  2.4118e-04,  5.2004e-03,\n",
      "          5.0727e-03, -2.0845e-03, -7.2142e-03, -6.2673e-04, -1.2068e-03,\n",
      "          2.8038e-03, -3.3053e-03, -5.8458e-03, -1.3588e-03, -1.1163e-02,\n",
      "          2.4458e-03,  5.3727e-03, -4.4535e-03,  1.7895e-03,  6.1375e-03,\n",
      "          6.8618e-03, -1.9009e-03,  2.2964e-03,  4.3752e-03, -9.8428e-04],\n",
      "        [-6.4355e-03, -1.9155e-03, -1.9827e-03, -7.4858e-05,  4.2387e-03,\n",
      "          2.0654e-03,  3.4809e-03,  5.2885e-04, -4.5808e-03,  2.3467e-03,\n",
      "         -7.4133e-03, -3.6432e-03, -1.1011e-03,  1.7849e-03,  1.2436e-03,\n",
      "          2.1718e-04, -2.4752e-05, -1.0338e-03,  2.8605e-05, -1.1141e-04,\n",
      "          6.5957e-03, -2.2248e-03, -7.1939e-04, -1.2582e-04, -1.5933e-03,\n",
      "          2.8413e-04,  1.1755e-03,  1.3185e-03,  3.4048e-04,  5.2416e-03,\n",
      "         -9.2178e-04,  3.7221e-04,  1.3847e-02,  3.4035e-03,  1.0252e-03,\n",
      "          8.0758e-04,  1.5134e-04,  2.5465e-03,  4.2728e-03, -1.3472e-03,\n",
      "          1.6038e-03, -9.2578e-03,  5.2702e-03, -2.2036e-03, -6.6720e-03,\n",
      "          3.6992e-03,  5.5809e-03,  2.9969e-04, -3.5200e-03,  3.4954e-04],\n",
      "        [-2.6273e-03, -1.2638e-03,  7.5205e-04, -3.0412e-04, -1.1347e-03,\n",
      "         -8.5461e-04,  1.3379e-03, -9.4398e-04,  4.7771e-04, -4.3105e-03,\n",
      "          9.6870e-04,  1.5752e-03,  1.1075e-03, -3.1053e-03, -1.0905e-04,\n",
      "         -2.4785e-03, -6.2771e-04,  3.0151e-03,  2.5240e-03,  4.5444e-04,\n",
      "         -2.8922e-03, -4.8959e-04, -5.3485e-04,  1.9947e-04,  1.2557e-03,\n",
      "          1.6207e-03,  3.7375e-04, -2.4393e-03, -5.4010e-04, -3.0701e-03,\n",
      "         -4.5853e-04,  8.6582e-05, -5.8335e-03,  3.6405e-03,  1.4892e-03,\n",
      "          1.0787e-03,  1.5522e-03,  4.4634e-03, -4.0373e-03,  3.6216e-03,\n",
      "          8.1371e-04,  6.4314e-04, -1.3688e-04,  7.1605e-04, -3.8697e-03,\n",
      "         -1.0341e-02, -6.7525e-03, -2.9437e-04, -8.1970e-03,  6.3331e-04],\n",
      "        [-4.9193e-03, -8.7471e-04,  7.3275e-04, -5.7591e-04,  2.5233e-03,\n",
      "          1.4417e-03,  3.7526e-03,  4.5439e-04, -3.6818e-03,  5.6800e-03,\n",
      "         -4.0139e-03,  1.2419e-03,  4.6638e-03,  2.9317e-03,  1.5341e-03,\n",
      "          8.9461e-03,  3.0547e-03,  1.7191e-03, -2.4625e-04,  2.6480e-03,\n",
      "          6.9880e-03,  1.0708e-03,  1.2231e-03,  1.2631e-03,  1.7345e-03,\n",
      "         -6.9656e-05, -3.1202e-04,  2.3185e-03,  3.1728e-04,  1.0730e-03,\n",
      "          5.5470e-05,  8.0373e-04,  9.5001e-03,  5.3537e-03,  6.5227e-04,\n",
      "          8.5402e-04, -1.3250e-03,  6.3525e-03,  2.6757e-03,  9.1293e-05,\n",
      "         -9.1851e-04, -7.1394e-03,  5.1983e-03,  8.7612e-04, -2.7479e-03,\n",
      "          5.1629e-03,  8.7482e-03, -1.7872e-03, -4.0322e-05, -8.5951e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1383, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0026, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "Epoch: 1 done. Test loss 2.3033180236816406. Test accuracy 0.1042\n",
      "Loss:  tensor(2.3027, grad_fn=<DivBackward1>)\n",
      "After zero grad\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0025, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0441,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0558, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0880,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1395,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0211,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0178,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0784,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0666, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1119,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1245, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0255,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0903,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0254,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1250,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0496,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1397, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0235,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1383, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  None\n",
      "After backwards\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0079, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0025, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0254,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0008, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0001, -0.0025,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0070, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0032, -0.0017, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0014, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0441,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0488, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0558, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0085, -0.1351,  0.1326,\n",
      "         -0.0809, -0.0880,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0694,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0745,  0.1156,  0.0291, -0.1395,  0.0171,\n",
      "         -0.1191,  0.0621, -0.0466, -0.1043,  0.0211,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0031,  0.0796,  0.0257, -0.0331, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0178,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0784,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0756, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0666, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0577, -0.0096,\n",
      "          0.0711, -0.0209, -0.0900, -0.1142, -0.0131,  0.0213,  0.0984,  0.0212,\n",
      "          0.0936, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1112, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0608, -0.1234,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1007, -0.1376, -0.0478, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1181,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1119,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1245, -0.0676, -0.1281,\n",
      "          0.0789,  0.0453],\n",
      "        [ 0.0726,  0.0255,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0903,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0254,  0.0517, -0.1181, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1250,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0496,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1397, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0411, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0235,  0.1156,  0.0158,  0.1147, -0.0968,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0280, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0641e-03, -8.6357e-04, -1.2440e-03, -3.9726e-03, -9.0065e-05,\n",
      "          3.4399e-03, -5.6828e-04,  2.9593e-04,  4.8608e-03, -7.8417e-03,\n",
      "         -2.8675e-03,  1.7188e-03,  1.5007e-03,  7.9963e-04,  1.7838e-03,\n",
      "         -9.2677e-03,  3.1975e-03, -7.2851e-03,  1.6735e-03,  9.8501e-04,\n",
      "         -1.1603e-02,  1.6943e-03,  3.7938e-03, -3.9867e-03,  9.7863e-04,\n",
      "         -1.0499e-04, -5.7453e-05,  7.8790e-03,  1.5043e-03, -5.0473e-03,\n",
      "         -1.6722e-02,  1.2236e-04, -3.8198e-03, -1.2347e-02, -4.1492e-03,\n",
      "         -8.2353e-03,  4.3422e-03, -6.4775e-03,  1.9044e-03, -1.1985e-02,\n",
      "          5.5419e-03,  2.8392e-03,  1.7657e-03, -6.9561e-03,  6.1386e-03,\n",
      "          3.7421e-03, -1.2417e-02,  1.3563e-05,  2.5436e-03, -2.1799e-03],\n",
      "        [ 3.4526e-03, -2.3516e-03,  1.0188e-03,  4.4651e-03,  3.4129e-03,\n",
      "         -3.1236e-04, -4.4931e-03, -2.5966e-03, -5.3800e-03,  4.0999e-03,\n",
      "          2.7747e-03, -5.8268e-03,  4.3849e-03, -7.5627e-03, -1.4370e-03,\n",
      "         -1.0168e-03, -5.4853e-03,  3.9572e-03, -3.7687e-03, -7.8288e-03,\n",
      "          1.0654e-02, -1.3122e-03, -8.0849e-03,  1.9871e-03,  2.2922e-03,\n",
      "          2.3056e-03,  1.8642e-03, -1.4390e-02,  1.3873e-03,  6.3469e-03,\n",
      "          1.4555e-02,  1.1270e-03,  8.8798e-03,  9.4674e-03,  1.9241e-03,\n",
      "          3.1582e-03, -1.1815e-03,  7.3314e-03,  6.6597e-03,  8.1476e-03,\n",
      "         -3.8742e-03,  7.6635e-03,  3.5451e-05,  4.6162e-03, -6.9205e-03,\n",
      "         -4.3586e-03,  7.4449e-04, -2.5258e-03,  6.3997e-03,  1.2892e-03],\n",
      "        [ 1.8764e-03,  2.6422e-03, -1.3655e-05,  3.3725e-03, -4.5854e-03,\n",
      "         -2.4051e-04, -2.1258e-03,  8.6686e-04,  3.7390e-03, -7.7304e-03,\n",
      "          1.7331e-03,  2.1403e-03, -1.0874e-03,  6.2087e-04, -1.0405e-04,\n",
      "         -5.2521e-03,  4.7779e-04,  1.9850e-03,  3.2196e-03, -3.3702e-03,\n",
      "         -3.3396e-03, -2.7755e-04,  2.4952e-03,  9.6700e-04,  3.5474e-04,\n",
      "         -2.7705e-03,  2.0431e-04, -1.2677e-03, -4.0595e-03,  3.4062e-03,\n",
      "         -1.9900e-03, -1.7534e-03, -3.5862e-03, -6.6280e-03,  1.3700e-03,\n",
      "          2.0808e-03, -3.7694e-04, -1.2838e-02, -1.0309e-03,  7.8929e-04,\n",
      "         -2.5213e-03,  1.5500e-03, -4.2987e-03,  1.8968e-03,  1.2254e-04,\n",
      "          2.9317e-03,  7.3505e-03,  1.3387e-03, -3.6591e-03, -3.4002e-04],\n",
      "        [ 1.0915e-03,  6.1664e-03, -3.8970e-04, -8.6756e-03,  7.4525e-04,\n",
      "         -3.0312e-03, -3.8284e-03, -3.0169e-04,  4.8303e-03,  1.9049e-03,\n",
      "          1.4426e-03,  2.4646e-03, -1.8769e-02,  2.3895e-03, -3.8894e-03,\n",
      "         -1.8730e-03, -2.2771e-03, -1.2230e-03, -2.0668e-03,  1.5528e-03,\n",
      "         -3.4449e-03, -1.5163e-03,  3.4072e-03,  1.1607e-03, -5.2397e-04,\n",
      "         -3.4579e-03, -8.4270e-04,  2.0199e-03,  5.6806e-04, -7.4181e-03,\n",
      "          6.2079e-03,  9.4991e-04, -1.4579e-02, -1.4892e-03, -2.1960e-04,\n",
      "         -1.6751e-03,  2.5377e-03,  4.9223e-04, -1.2839e-03,  7.7330e-03,\n",
      "         -2.0700e-03,  3.2497e-04, -6.1810e-03,  2.4565e-03,  2.6209e-03,\n",
      "         -4.8327e-03, -1.3888e-03, -5.7199e-04, -1.9843e-03,  9.9250e-04],\n",
      "        [-1.8647e-03,  2.8219e-03,  4.6892e-04,  1.9413e-03, -3.1562e-03,\n",
      "         -3.8488e-03,  5.0710e-03,  6.2742e-04,  8.3953e-04,  1.4321e-03,\n",
      "          1.8487e-03,  3.6095e-03,  3.3577e-03,  5.7474e-03,  7.2310e-04,\n",
      "          1.1090e-02, -1.0347e-03,  5.7031e-04,  1.2077e-03,  2.4617e-03,\n",
      "         -2.3822e-03,  9.0333e-04, -1.4156e-03,  1.1232e-03,  9.7153e-04,\n",
      "         -8.7243e-04, -1.2850e-03,  1.6769e-03, -2.2106e-04, -1.4374e-03,\n",
      "         -1.6676e-03,  5.9329e-04,  1.0278e-02, -1.4489e-03, -3.2434e-05,\n",
      "          2.1013e-03, -2.9742e-03,  1.1802e-03, -5.5978e-03, -1.8147e-03,\n",
      "         -3.0776e-04, -4.5761e-03,  2.5040e-03, -2.3662e-03, -4.0249e-04,\n",
      "         -3.0767e-03,  1.1034e-02,  1.3363e-03,  2.2481e-03,  2.1735e-05],\n",
      "        [ 3.0931e-03, -1.3640e-03, -6.6468e-05, -6.5903e-04, -5.6126e-04,\n",
      "         -1.0626e-03, -2.0550e-03, -3.1587e-04, -9.6325e-04,  1.1664e-03,\n",
      "          1.1004e-03, -2.8574e-03, -1.7975e-03, -1.6304e-03, -2.8347e-04,\n",
      "          2.8583e-03,  2.0455e-03, -3.0048e-04, -3.0518e-03,  1.0468e-03,\n",
      "          2.0174e-03,  7.6158e-04, -2.5160e-03, -2.7893e-03,  1.0425e-03,\n",
      "          1.2785e-03, -2.1130e-03,  3.0053e-03,  4.6040e-04, -4.3086e-03,\n",
      "         -4.1271e-03, -2.1677e-04, -7.4320e-03,  6.9465e-04, -8.5906e-04,\n",
      "         -2.9782e-03,  5.6626e-04,  2.7923e-03, -2.2150e-03,  5.9230e-03,\n",
      "         -7.1480e-04,  2.5851e-03,  3.1643e-04, -8.3254e-04,  5.5991e-03,\n",
      "          2.0136e-04, -1.0984e-02, -1.0988e-04,  1.8274e-03,  3.0430e-04],\n",
      "        [ 2.2695e-03, -2.9981e-03,  7.2421e-04,  4.4806e-03, -1.3917e-03,\n",
      "          2.3995e-03, -5.8932e-04,  1.3846e-03, -1.6151e-04,  3.2508e-03,\n",
      "          4.4428e-03, -4.1830e-04,  7.7559e-03, -1.9644e-03,  5.3391e-04,\n",
      "         -3.2246e-03,  6.8260e-04, -1.3913e-03,  4.8614e-04,  2.1566e-03,\n",
      "         -2.6123e-03,  1.3962e-03,  2.3524e-03,  2.0156e-04, -6.5235e-03,\n",
      "          1.7951e-03,  9.9716e-04, -1.3228e-04,  2.4037e-04,  5.2014e-03,\n",
      "          5.0596e-03, -2.0854e-03, -7.2266e-03, -6.3574e-04, -1.2118e-03,\n",
      "          2.8056e-03, -3.2960e-03, -5.8355e-03, -1.3587e-03, -1.1146e-02,\n",
      "          2.4491e-03,  5.3736e-03, -4.4458e-03,  1.7897e-03,  6.1304e-03,\n",
      "          6.8721e-03, -1.8948e-03,  2.2970e-03,  4.3730e-03, -9.8483e-04],\n",
      "        [-6.4350e-03, -1.9098e-03, -1.9831e-03, -7.4989e-05,  4.2383e-03,\n",
      "          2.0646e-03,  3.4876e-03,  5.2799e-04, -4.5684e-03,  2.3464e-03,\n",
      "         -7.4219e-03, -3.6463e-03, -1.1132e-03,  1.7730e-03,  1.2457e-03,\n",
      "          2.1477e-04, -3.3185e-05, -1.0314e-03,  2.4587e-05, -1.0898e-04,\n",
      "          6.6058e-03, -2.2288e-03, -7.2361e-04, -1.2536e-04, -1.5871e-03,\n",
      "          2.8222e-04,  1.1709e-03,  1.3241e-03,  3.4083e-04,  5.2544e-03,\n",
      "         -9.1538e-04,  3.7232e-04,  1.3835e-02,  3.4051e-03,  1.0293e-03,\n",
      "          8.0830e-04,  1.5386e-04,  2.5412e-03,  4.2797e-03, -1.3528e-03,\n",
      "          1.6032e-03, -9.2627e-03,  5.2538e-03, -2.2004e-03, -6.6750e-03,\n",
      "          3.7038e-03,  5.5693e-03,  3.0077e-04, -3.5155e-03,  3.4961e-04],\n",
      "        [-2.6272e-03, -1.2703e-03,  7.5216e-04, -3.0284e-04, -1.1332e-03,\n",
      "         -8.5240e-04,  1.3400e-03, -9.4257e-04,  4.7758e-04, -4.3117e-03,\n",
      "          9.6732e-04,  1.5795e-03,  1.1076e-03, -3.0934e-03, -1.0899e-04,\n",
      "         -2.4738e-03, -6.2181e-04,  3.0055e-03,  2.5240e-03,  4.5395e-04,\n",
      "         -2.8926e-03, -4.9403e-04, -5.3167e-04,  2.0028e-04,  1.2584e-03,\n",
      "          1.6167e-03,  3.7445e-04, -2.4417e-03, -5.3872e-04, -3.0774e-03,\n",
      "         -4.5532e-04,  8.6466e-05, -5.8291e-03,  3.6374e-03,  1.4941e-03,\n",
      "          1.0790e-03,  1.5491e-03,  4.4634e-03, -4.0407e-03,  3.6181e-03,\n",
      "          8.1298e-04,  6.4186e-04, -1.3266e-04,  7.1623e-04, -3.8576e-03,\n",
      "         -1.0350e-02, -6.7567e-03, -2.9366e-04, -8.1970e-03,  6.3329e-04],\n",
      "        [-4.9204e-03, -8.7322e-04,  7.3284e-04, -5.7447e-04,  2.5214e-03,\n",
      "          1.4439e-03,  3.7612e-03,  4.5392e-04, -3.6740e-03,  5.6834e-03,\n",
      "         -4.0202e-03,  1.2361e-03,  4.6606e-03,  2.9207e-03,  1.5364e-03,\n",
      "          8.9451e-03,  3.0488e-03,  1.7131e-03, -2.4819e-04,  2.6512e-03,\n",
      "          6.9977e-03,  1.0735e-03,  1.2231e-03,  1.2615e-03,  1.7366e-03,\n",
      "         -7.2352e-05, -3.1297e-04,  2.3264e-03,  3.1799e-04,  1.0800e-03,\n",
      "          5.4031e-05,  8.0422e-04,  9.4795e-03,  5.3446e-03,  6.5458e-04,\n",
      "          8.5537e-04, -1.3206e-03,  6.3503e-03,  2.6834e-03,  8.8218e-05,\n",
      "         -9.1915e-04, -7.1394e-03,  5.1827e-03,  8.7979e-04, -2.7561e-03,\n",
      "          5.1674e-03,  8.7429e-03, -1.7851e-03, -3.5872e-05, -8.5847e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1383, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0026, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "After optimization step\n",
      "Parameter name:  hidden.weight\n",
      "Parameter shape:  torch.Size([50, 784])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0248, -0.0255, -0.0022,  ...,  0.0128,  0.0226, -0.0343],\n",
      "        [ 0.0022,  0.0083, -0.0131,  ..., -0.0083,  0.0130,  0.0020],\n",
      "        [-0.0183,  0.0001, -0.0179,  ...,  0.0127, -0.0327, -0.0273],\n",
      "        ...,\n",
      "        [-0.0250,  0.0308, -0.0327,  ...,  0.0019,  0.0334, -0.0356],\n",
      "        [ 0.0151,  0.0056,  0.0210,  ...,  0.0216, -0.0341, -0.0346],\n",
      "        [-0.0199,  0.0284,  0.0199,  ...,  0.0332, -0.0357, -0.0035]],\n",
      "       requires_grad=True)\n",
      "Parameter grad:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter name:  hidden.bias\n",
      "Parameter shape:  torch.Size([50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([ 0.0043,  0.0058,  0.0029, -0.0113,  0.0036, -0.0087,  0.0347, -0.0299,\n",
      "        -0.0029, -0.0249,  0.0288,  0.0263, -0.0348,  0.0078, -0.0210,  0.0187,\n",
      "         0.0164,  0.0307,  0.0025, -0.0235, -0.0357, -0.0016,  0.0269, -0.0076,\n",
      "        -0.0063,  0.0317,  0.0025, -0.0044,  0.0189, -0.0127, -0.0157, -0.0057,\n",
      "        -0.0198,  0.0127,  0.0023, -0.0047,  0.0253,  0.0304, -0.0107, -0.0167,\n",
      "         0.0134,  0.0138,  0.0101, -0.0339,  0.0061,  0.0210, -0.0122, -0.0077,\n",
      "         0.0309, -0.0184], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0003,  0.0011, -0.0007, -0.0011, -0.0014,  0.0008, -0.0023,  0.0022,\n",
      "         0.0059, -0.0026, -0.0049,  0.0001, -0.0025,  0.0077, -0.0047, -0.0019,\n",
      "         0.0014,  0.0097,  0.0012, -0.0032, -0.0038, -0.0070, -0.0029,  0.0024,\n",
      "        -0.0031,  0.0064,  0.0062, -0.0023,  0.0001, -0.0032, -0.0017, -0.0010,\n",
      "         0.0029,  0.0059, -0.0065, -0.0022,  0.0049, -0.0018,  0.0018,  0.0044,\n",
      "        -0.0014, -0.0004,  0.0060, -0.0008,  0.0047, -0.0009,  0.0006, -0.0007,\n",
      "        -0.0003, -0.0007])\n",
      "Parameter name:  output.weight\n",
      "Parameter shape:  torch.Size([10, 50])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([[ 0.0801, -0.1313, -0.0441,  0.0818, -0.1118,  0.0655,  0.0215, -0.1404,\n",
      "          0.0642,  0.0489, -0.1353,  0.1250,  0.0784, -0.0622, -0.0855, -0.0739,\n",
      "          0.0558, -0.0641,  0.0921,  0.1162,  0.1341, -0.1233,  0.1054,  0.0236,\n",
      "          0.0138, -0.0022, -0.1285,  0.0795,  0.0397, -0.0084, -0.1350,  0.1326,\n",
      "         -0.0809, -0.0880,  0.0879, -0.0614, -0.0328,  0.0402,  0.0290,  0.0064,\n",
      "          0.0445,  0.0661, -0.0073,  0.0704, -0.0346,  0.1092,  0.0469,  0.0899,\n",
      "          0.0052, -0.0077],\n",
      "        [ 0.0942,  0.1219, -0.0627, -0.1184, -0.0438,  0.0970, -0.1186, -0.0494,\n",
      "          0.0139, -0.0536,  0.0966, -0.1034, -0.0533, -0.0453,  0.0662,  0.0318,\n",
      "         -0.0693,  0.0236,  0.0099,  0.0518, -0.1373,  0.0098,  0.0551,  0.0533,\n",
      "         -0.0618,  0.1115,  0.1411,  0.0746,  0.1156,  0.0291, -0.1395,  0.0171,\n",
      "         -0.1192,  0.0620, -0.0466, -0.1043,  0.0211,  0.1353,  0.0774,  0.1032,\n",
      "          0.1169, -0.0032,  0.0796,  0.0257, -0.0330, -0.0678, -0.0232, -0.0166,\n",
      "         -0.0509,  0.0567],\n",
      "        [ 0.0539,  0.0952,  0.0578,  0.0322,  0.0251,  0.1339, -0.0334,  0.0952,\n",
      "          0.1186, -0.0372,  0.0374, -0.1109, -0.0755, -0.1087,  0.0323,  0.0178,\n",
      "         -0.0532, -0.0010,  0.1220,  0.0784,  0.1179, -0.1074,  0.0914, -0.0501,\n",
      "         -0.1252, -0.0609, -0.0801,  0.0967,  0.0688,  0.0396,  0.0855,  0.0320,\n",
      "         -0.0425, -0.0755, -0.0257,  0.1163,  0.0767,  0.0937, -0.0062, -0.0405,\n",
      "         -0.0692, -0.1054, -0.0666, -0.0671,  0.0617,  0.0046, -0.0597,  0.0546,\n",
      "          0.0157, -0.0296],\n",
      "        [ 0.0048,  0.0298, -0.0937,  0.0120,  0.1151, -0.1103,  0.0578, -0.0096,\n",
      "          0.0710, -0.0209, -0.0900, -0.1142, -0.0130,  0.0213,  0.0984,  0.0212,\n",
      "          0.0937, -0.0703,  0.0967,  0.0382, -0.0113,  0.0705, -0.0579, -0.1004,\n",
      "         -0.0280, -0.0558, -0.1346, -0.0331,  0.0030,  0.1334, -0.0746,  0.0076,\n",
      "         -0.0255,  0.0108, -0.1197,  0.0426,  0.0983,  0.1201,  0.0984,  0.0851,\n",
      "          0.1113, -0.0023, -0.0973, -0.0589,  0.1001,  0.0374, -0.1412,  0.0749,\n",
      "          0.1200, -0.1314],\n",
      "        [ 0.0741,  0.0666, -0.0179,  0.0570,  0.0861, -0.0070, -0.1231, -0.1243,\n",
      "          0.0652, -0.0110, -0.1318,  0.1221, -0.1021,  0.1293, -0.1037,  0.0353,\n",
      "         -0.0295, -0.1395,  0.0786,  0.1297, -0.0359, -0.0424,  0.0706,  0.1241,\n",
      "          0.1062, -0.0742,  0.0638, -0.0852,  0.0161,  0.1142,  0.1397, -0.0711,\n",
      "          0.0214, -0.0057, -0.0180, -0.0609, -0.1233,  0.1224, -0.0875,  0.0138,\n",
      "          0.0292,  0.0007,  0.1040, -0.0906,  0.1231, -0.1328, -0.0908,  0.0994,\n",
      "         -0.0986, -0.0822],\n",
      "        [ 0.1010, -0.0373,  0.1043,  0.0954, -0.0646, -0.0962, -0.1114,  0.0495,\n",
      "          0.1258,  0.0956, -0.0283,  0.1008, -0.1376, -0.0477, -0.0277,  0.1033,\n",
      "          0.0041,  0.0079,  0.1229,  0.0835, -0.1121,  0.0852, -0.1008, -0.1045,\n",
      "         -0.0495,  0.1057, -0.0835, -0.0954, -0.1359,  0.0198,  0.0005, -0.0997,\n",
      "          0.0960, -0.1011,  0.0835,  0.0441, -0.0905, -0.1081,  0.0764, -0.0355,\n",
      "         -0.0768, -0.0629, -0.0038, -0.0586,  0.1029, -0.1375, -0.1180,  0.0698,\n",
      "         -0.0461, -0.1194],\n",
      "        [ 0.1203,  0.1029,  0.0903,  0.0865, -0.0231,  0.0567, -0.0432,  0.0559,\n",
      "          0.1296, -0.1198, -0.0979,  0.0103, -0.0819,  0.0677,  0.0509,  0.1144,\n",
      "         -0.0695, -0.0667, -0.0459, -0.1252, -0.1107, -0.1271, -0.0630,  0.1045,\n",
      "          0.1009,  0.0499,  0.0367,  0.0661,  0.1125,  0.0872, -0.0098,  0.0647,\n",
      "          0.1336,  0.1119,  0.0195, -0.0122, -0.1005, -0.0901,  0.0132, -0.0311,\n",
      "          0.0291,  0.0758, -0.1380,  0.0432,  0.0827, -0.1245, -0.0676, -0.1281,\n",
      "          0.0788,  0.0453],\n",
      "        [ 0.0727,  0.0255,  0.0065,  0.0630, -0.0081, -0.0854, -0.0618,  0.0518,\n",
      "          0.0163,  0.0903,  0.0376, -0.0005,  0.0624,  0.0992,  0.0556,  0.0920,\n",
      "          0.0350, -0.1213,  0.1331, -0.0942, -0.0751, -0.0081,  0.1022, -0.0843,\n",
      "         -0.1063,  0.0237,  0.1329,  0.0254,  0.0517, -0.1182, -0.0978,  0.0488,\n",
      "          0.0587, -0.0975, -0.0632,  0.0271, -0.1047,  0.0706, -0.1250,  0.0706,\n",
      "          0.0291,  0.1008, -0.0255, -0.0391,  0.0181, -0.0496,  0.0746, -0.0041,\n",
      "         -0.0123, -0.0116],\n",
      "        [ 0.0950,  0.1382,  0.0097,  0.0547, -0.0976,  0.0018, -0.0959, -0.0741,\n",
      "          0.1253, -0.0400,  0.0011, -0.0132,  0.0101, -0.0658, -0.1310, -0.0644,\n",
      "         -0.1192,  0.1119, -0.0181,  0.0094, -0.0460,  0.1280, -0.0787, -0.1063,\n",
      "         -0.1205,  0.0349,  0.1399,  0.0711, -0.1024,  0.0838, -0.1412,  0.1160,\n",
      "          0.0206,  0.0659, -0.0372, -0.1305,  0.1120, -0.0835,  0.0073,  0.0579,\n",
      "          0.0713,  0.1215, -0.0390,  0.0634, -0.1297,  0.0911,  0.1397, -0.0869,\n",
      "         -0.0360,  0.0985],\n",
      "        [ 0.0936, -0.0525, -0.1352, -0.0453, -0.0412, -0.0098, -0.0490, -0.0202,\n",
      "         -0.0999, -0.0436,  0.0284, -0.0235,  0.1156,  0.0158,  0.1147, -0.0969,\n",
      "          0.0639,  0.0820,  0.0868, -0.0592,  0.1262, -0.0623, -0.0778,  0.1223,\n",
      "         -0.1283,  0.0364,  0.0705, -0.0172, -0.1394, -0.0800, -0.1310,  0.0130,\n",
      "          0.1243,  0.0830, -0.0968, -0.1192,  0.0241, -0.0281, -0.1179,  0.0044,\n",
      "          0.0705, -0.0545,  0.1382, -0.0936,  0.1368,  0.0923, -0.0128, -0.0729,\n",
      "          0.0480, -0.0357]], requires_grad=True)\n",
      "Parameter grad:  tensor([[ 4.0641e-03, -8.6357e-04, -1.2440e-03, -3.9726e-03, -9.0065e-05,\n",
      "          3.4399e-03, -5.6828e-04,  2.9593e-04,  4.8608e-03, -7.8417e-03,\n",
      "         -2.8675e-03,  1.7188e-03,  1.5007e-03,  7.9963e-04,  1.7838e-03,\n",
      "         -9.2677e-03,  3.1975e-03, -7.2851e-03,  1.6735e-03,  9.8501e-04,\n",
      "         -1.1603e-02,  1.6943e-03,  3.7938e-03, -3.9867e-03,  9.7863e-04,\n",
      "         -1.0499e-04, -5.7453e-05,  7.8790e-03,  1.5043e-03, -5.0473e-03,\n",
      "         -1.6722e-02,  1.2236e-04, -3.8198e-03, -1.2347e-02, -4.1492e-03,\n",
      "         -8.2353e-03,  4.3422e-03, -6.4775e-03,  1.9044e-03, -1.1985e-02,\n",
      "          5.5419e-03,  2.8392e-03,  1.7657e-03, -6.9561e-03,  6.1386e-03,\n",
      "          3.7421e-03, -1.2417e-02,  1.3563e-05,  2.5436e-03, -2.1799e-03],\n",
      "        [ 3.4526e-03, -2.3516e-03,  1.0188e-03,  4.4651e-03,  3.4129e-03,\n",
      "         -3.1236e-04, -4.4931e-03, -2.5966e-03, -5.3800e-03,  4.0999e-03,\n",
      "          2.7747e-03, -5.8268e-03,  4.3849e-03, -7.5627e-03, -1.4370e-03,\n",
      "         -1.0168e-03, -5.4853e-03,  3.9572e-03, -3.7687e-03, -7.8288e-03,\n",
      "          1.0654e-02, -1.3122e-03, -8.0849e-03,  1.9871e-03,  2.2922e-03,\n",
      "          2.3056e-03,  1.8642e-03, -1.4390e-02,  1.3873e-03,  6.3469e-03,\n",
      "          1.4555e-02,  1.1270e-03,  8.8798e-03,  9.4674e-03,  1.9241e-03,\n",
      "          3.1582e-03, -1.1815e-03,  7.3314e-03,  6.6597e-03,  8.1476e-03,\n",
      "         -3.8742e-03,  7.6635e-03,  3.5451e-05,  4.6162e-03, -6.9205e-03,\n",
      "         -4.3586e-03,  7.4449e-04, -2.5258e-03,  6.3997e-03,  1.2892e-03],\n",
      "        [ 1.8764e-03,  2.6422e-03, -1.3655e-05,  3.3725e-03, -4.5854e-03,\n",
      "         -2.4051e-04, -2.1258e-03,  8.6686e-04,  3.7390e-03, -7.7304e-03,\n",
      "          1.7331e-03,  2.1403e-03, -1.0874e-03,  6.2087e-04, -1.0405e-04,\n",
      "         -5.2521e-03,  4.7779e-04,  1.9850e-03,  3.2196e-03, -3.3702e-03,\n",
      "         -3.3396e-03, -2.7755e-04,  2.4952e-03,  9.6700e-04,  3.5474e-04,\n",
      "         -2.7705e-03,  2.0431e-04, -1.2677e-03, -4.0595e-03,  3.4062e-03,\n",
      "         -1.9900e-03, -1.7534e-03, -3.5862e-03, -6.6280e-03,  1.3700e-03,\n",
      "          2.0808e-03, -3.7694e-04, -1.2838e-02, -1.0309e-03,  7.8929e-04,\n",
      "         -2.5213e-03,  1.5500e-03, -4.2987e-03,  1.8968e-03,  1.2254e-04,\n",
      "          2.9317e-03,  7.3505e-03,  1.3387e-03, -3.6591e-03, -3.4002e-04],\n",
      "        [ 1.0915e-03,  6.1664e-03, -3.8970e-04, -8.6756e-03,  7.4525e-04,\n",
      "         -3.0312e-03, -3.8284e-03, -3.0169e-04,  4.8303e-03,  1.9049e-03,\n",
      "          1.4426e-03,  2.4646e-03, -1.8769e-02,  2.3895e-03, -3.8894e-03,\n",
      "         -1.8730e-03, -2.2771e-03, -1.2230e-03, -2.0668e-03,  1.5528e-03,\n",
      "         -3.4449e-03, -1.5163e-03,  3.4072e-03,  1.1607e-03, -5.2397e-04,\n",
      "         -3.4579e-03, -8.4270e-04,  2.0199e-03,  5.6806e-04, -7.4181e-03,\n",
      "          6.2079e-03,  9.4991e-04, -1.4579e-02, -1.4892e-03, -2.1960e-04,\n",
      "         -1.6751e-03,  2.5377e-03,  4.9223e-04, -1.2839e-03,  7.7330e-03,\n",
      "         -2.0700e-03,  3.2497e-04, -6.1810e-03,  2.4565e-03,  2.6209e-03,\n",
      "         -4.8327e-03, -1.3888e-03, -5.7199e-04, -1.9843e-03,  9.9250e-04],\n",
      "        [-1.8647e-03,  2.8219e-03,  4.6892e-04,  1.9413e-03, -3.1562e-03,\n",
      "         -3.8488e-03,  5.0710e-03,  6.2742e-04,  8.3953e-04,  1.4321e-03,\n",
      "          1.8487e-03,  3.6095e-03,  3.3577e-03,  5.7474e-03,  7.2310e-04,\n",
      "          1.1090e-02, -1.0347e-03,  5.7031e-04,  1.2077e-03,  2.4617e-03,\n",
      "         -2.3822e-03,  9.0333e-04, -1.4156e-03,  1.1232e-03,  9.7153e-04,\n",
      "         -8.7243e-04, -1.2850e-03,  1.6769e-03, -2.2106e-04, -1.4374e-03,\n",
      "         -1.6676e-03,  5.9329e-04,  1.0278e-02, -1.4489e-03, -3.2434e-05,\n",
      "          2.1013e-03, -2.9742e-03,  1.1802e-03, -5.5978e-03, -1.8147e-03,\n",
      "         -3.0776e-04, -4.5761e-03,  2.5040e-03, -2.3662e-03, -4.0249e-04,\n",
      "         -3.0767e-03,  1.1034e-02,  1.3363e-03,  2.2481e-03,  2.1735e-05],\n",
      "        [ 3.0931e-03, -1.3640e-03, -6.6468e-05, -6.5903e-04, -5.6126e-04,\n",
      "         -1.0626e-03, -2.0550e-03, -3.1587e-04, -9.6325e-04,  1.1664e-03,\n",
      "          1.1004e-03, -2.8574e-03, -1.7975e-03, -1.6304e-03, -2.8347e-04,\n",
      "          2.8583e-03,  2.0455e-03, -3.0048e-04, -3.0518e-03,  1.0468e-03,\n",
      "          2.0174e-03,  7.6158e-04, -2.5160e-03, -2.7893e-03,  1.0425e-03,\n",
      "          1.2785e-03, -2.1130e-03,  3.0053e-03,  4.6040e-04, -4.3086e-03,\n",
      "         -4.1271e-03, -2.1677e-04, -7.4320e-03,  6.9465e-04, -8.5906e-04,\n",
      "         -2.9782e-03,  5.6626e-04,  2.7923e-03, -2.2150e-03,  5.9230e-03,\n",
      "         -7.1480e-04,  2.5851e-03,  3.1643e-04, -8.3254e-04,  5.5991e-03,\n",
      "          2.0136e-04, -1.0984e-02, -1.0988e-04,  1.8274e-03,  3.0430e-04],\n",
      "        [ 2.2695e-03, -2.9981e-03,  7.2421e-04,  4.4806e-03, -1.3917e-03,\n",
      "          2.3995e-03, -5.8932e-04,  1.3846e-03, -1.6151e-04,  3.2508e-03,\n",
      "          4.4428e-03, -4.1830e-04,  7.7559e-03, -1.9644e-03,  5.3391e-04,\n",
      "         -3.2246e-03,  6.8260e-04, -1.3913e-03,  4.8614e-04,  2.1566e-03,\n",
      "         -2.6123e-03,  1.3962e-03,  2.3524e-03,  2.0156e-04, -6.5235e-03,\n",
      "          1.7951e-03,  9.9716e-04, -1.3228e-04,  2.4037e-04,  5.2014e-03,\n",
      "          5.0596e-03, -2.0854e-03, -7.2266e-03, -6.3574e-04, -1.2118e-03,\n",
      "          2.8056e-03, -3.2960e-03, -5.8355e-03, -1.3587e-03, -1.1146e-02,\n",
      "          2.4491e-03,  5.3736e-03, -4.4458e-03,  1.7897e-03,  6.1304e-03,\n",
      "          6.8721e-03, -1.8948e-03,  2.2970e-03,  4.3730e-03, -9.8483e-04],\n",
      "        [-6.4350e-03, -1.9098e-03, -1.9831e-03, -7.4989e-05,  4.2383e-03,\n",
      "          2.0646e-03,  3.4876e-03,  5.2799e-04, -4.5684e-03,  2.3464e-03,\n",
      "         -7.4219e-03, -3.6463e-03, -1.1132e-03,  1.7730e-03,  1.2457e-03,\n",
      "          2.1477e-04, -3.3185e-05, -1.0314e-03,  2.4587e-05, -1.0898e-04,\n",
      "          6.6058e-03, -2.2288e-03, -7.2361e-04, -1.2536e-04, -1.5871e-03,\n",
      "          2.8222e-04,  1.1709e-03,  1.3241e-03,  3.4083e-04,  5.2544e-03,\n",
      "         -9.1538e-04,  3.7232e-04,  1.3835e-02,  3.4051e-03,  1.0293e-03,\n",
      "          8.0830e-04,  1.5386e-04,  2.5412e-03,  4.2797e-03, -1.3528e-03,\n",
      "          1.6032e-03, -9.2627e-03,  5.2538e-03, -2.2004e-03, -6.6750e-03,\n",
      "          3.7038e-03,  5.5693e-03,  3.0077e-04, -3.5155e-03,  3.4961e-04],\n",
      "        [-2.6272e-03, -1.2703e-03,  7.5216e-04, -3.0284e-04, -1.1332e-03,\n",
      "         -8.5240e-04,  1.3400e-03, -9.4257e-04,  4.7758e-04, -4.3117e-03,\n",
      "          9.6732e-04,  1.5795e-03,  1.1076e-03, -3.0934e-03, -1.0899e-04,\n",
      "         -2.4738e-03, -6.2181e-04,  3.0055e-03,  2.5240e-03,  4.5395e-04,\n",
      "         -2.8926e-03, -4.9403e-04, -5.3167e-04,  2.0028e-04,  1.2584e-03,\n",
      "          1.6167e-03,  3.7445e-04, -2.4417e-03, -5.3872e-04, -3.0774e-03,\n",
      "         -4.5532e-04,  8.6466e-05, -5.8291e-03,  3.6374e-03,  1.4941e-03,\n",
      "          1.0790e-03,  1.5491e-03,  4.4634e-03, -4.0407e-03,  3.6181e-03,\n",
      "          8.1298e-04,  6.4186e-04, -1.3266e-04,  7.1623e-04, -3.8576e-03,\n",
      "         -1.0350e-02, -6.7567e-03, -2.9366e-04, -8.1970e-03,  6.3329e-04],\n",
      "        [-4.9204e-03, -8.7322e-04,  7.3284e-04, -5.7447e-04,  2.5214e-03,\n",
      "          1.4439e-03,  3.7612e-03,  4.5392e-04, -3.6740e-03,  5.6834e-03,\n",
      "         -4.0202e-03,  1.2361e-03,  4.6606e-03,  2.9207e-03,  1.5364e-03,\n",
      "          8.9451e-03,  3.0488e-03,  1.7131e-03, -2.4819e-04,  2.6512e-03,\n",
      "          6.9977e-03,  1.0735e-03,  1.2231e-03,  1.2615e-03,  1.7366e-03,\n",
      "         -7.2352e-05, -3.1297e-04,  2.3264e-03,  3.1799e-04,  1.0800e-03,\n",
      "          5.4031e-05,  8.0422e-04,  9.4795e-03,  5.3446e-03,  6.5458e-04,\n",
      "          8.5537e-04, -1.3206e-03,  6.3503e-03,  2.6834e-03,  8.8218e-05,\n",
      "         -9.1915e-04, -7.1394e-03,  5.1827e-03,  8.7979e-04, -2.7561e-03,\n",
      "          5.1674e-03,  8.7429e-03, -1.7851e-03, -3.5872e-05, -8.5847e-05]])\n",
      "Parameter name:  output.bias\n",
      "Parameter shape:  torch.Size([10])\n",
      "Parameter values:  Parameter containing:\n",
      "tensor([-0.1204,  0.1062, -0.0719, -0.0571, -0.0729, -0.1383, -0.1143, -0.0158,\n",
      "         0.0111,  0.0808], requires_grad=True)\n",
      "Parameter grad:  tensor([-0.0067, -0.0036, -0.0026, -0.0028,  0.0015, -0.0059, -0.0017,  0.0005,\n",
      "         0.0074,  0.0140])\n",
      "Epoch: 2 done. Test loss 2.3031399250030518. Test accuracy 0.1051\n"
     ]
    }
   ],
   "source": [
    "#calculating the accuracy given outputs not softmaxed and labels one hot encoding.\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    #don't need to softmax because the max value will be the max softmax we just pull the index to get the digit prediction \n",
    "    _, output_index = torch.max(outputs,1)\n",
    "    #get the index/ digit of the label\n",
    "    _, label_index = torch.max(labels, 1)\n",
    "    # return the number of correct matches and divide by the size to get accuracy\n",
    "    return (output_index == label_index).sum().item()/labels.size(0)\n",
    "\n",
    "\n",
    "#training loop function\n",
    "def training_loop(train_loader, test_loader, num_epochs, model, loss_function, optimizer):\n",
    "    #arrays for our plots\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    test_loss = []\n",
    "    test_accuracy =[]\n",
    "    #Setting up the training loop\n",
    "    print(\"Starting the Training Loop\")\n",
    "    for epoch in range(num_epochs):\n",
    "        #keep the loss and accuracies after each mini batch\n",
    "        batch_loss = []\n",
    "        batch_accuracy = []\n",
    "        #loop through a mini-batch on the same train loadear\n",
    "        for batch_index, (data, label) in enumerate(train_loader):\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            #evaluate the loss\n",
    "            loss = loss_function(outputs, label)\n",
    "            print(\"Loss: \", loss)\n",
    "            #append the loss to the batch loss\n",
    "            batch_loss.append(loss.item())\n",
    "            #calculate the accuracy based on the outputs (not softmaxed) and labels. Do outputs.data so we don't pass gradient info\n",
    "            batch_accuracy.append(calculate_accuracy(outputs.data, label))\n",
    "            # Backward pass setting gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            print(\"After zero grad\")\n",
    "            for name, param in model.named_parameters():\n",
    "                print(\"Parameter name: \", name)\n",
    "                print(\"Parameter shape: \", param.shape)\n",
    "                print(\"Parameter values: \", param)\n",
    "                print(\"Parameter grad: \", param.grad)\n",
    "            #calcualting gradients\n",
    "            loss.backward()\n",
    "            print(\"After backwards\")\n",
    "            for name, param in model.named_parameters():\n",
    "                print(\"Parameter name: \", name)\n",
    "                print(\"Parameter shape: \", param.shape)\n",
    "                print(\"Parameter values: \", param)\n",
    "                print(\"Parameter grad: \", param.grad)\n",
    "\n",
    "            #updating parameters\n",
    "            optimizer.step()\n",
    "            print(\"After optimization step\")\n",
    "            for name, param in model.named_parameters():\n",
    "                print(\"Parameter name: \", name)\n",
    "                print(\"Parameter shape: \", param.shape)\n",
    "                print(\"Parameter values: \", param)\n",
    "                print(\"Parameter grad: \", param.grad)\n",
    "\n",
    "        #add to the training epoch accuracies and losses\n",
    "        training_accuracy.append(np.average(batch_accuracy))\n",
    "        training_loss.append(np.average(batch_loss))\n",
    "        #get the test loss and accuracy\n",
    "        #change mode\n",
    "        model.eval()\n",
    "        #so we don't accidentally change anything\n",
    "        with torch.no_grad():\n",
    "            #get the \"batch\" of the test data which is all of it\n",
    "            for batch_index, (data, label) in enumerate(test_loader):\n",
    "                #get our test predicitons\n",
    "                test_predictions = model(data)\n",
    "                #test loss and move to cpu so I can plot\n",
    "                loss = loss_function(test_predictions, label).to(\"cpu\")\n",
    "                #append statistics\n",
    "                test_loss.append(loss)\n",
    "                test_accuracy.append(calculate_accuracy(test_predictions.data, label))\n",
    "        #back to training mode\n",
    "        model.train()\n",
    "        #printing\n",
    "        print(f\"Epoch: {epoch} done. Test loss {test_loss[epoch]}. Test accuracy {test_accuracy[epoch]}\")\n",
    "    return training_loss, training_accuracy, test_loss, test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "class OneLayer(torch.nn.Module):\n",
    "    def __init__(self, input_size = 784, hidden_size = 50, output_size = 10):\n",
    "        super().__init__()\n",
    "        #First hiddent layer\n",
    "        self.hidden = torch.nn.Linear(input_size, hidden_size)\n",
    "        #ReLU activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        #output layer\n",
    "        self.output = torch.nn.Linear(hidden_size, output_size)\n",
    "    #forward pass through the network\n",
    "    def forward(self, x):\n",
    "        #pass through first hidden layer\n",
    "\n",
    "        #the shape of the input is [batch size, image size flattened]\n",
    "        #print(\"x at start: \", x.shape)\n",
    "        x = self.hidden(x)\n",
    "        #activation function\n",
    "        x = self.relu(x)\n",
    "        #pass through the output layer\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# setting the hyperparameters for exercise 1\n",
    "input_size_1 = 784\n",
    "num_classes_1 = 10\n",
    "learning_rate_1 = 0.001\n",
    "num_epochs_1 = 3\n",
    "\n",
    "\n",
    "#This is the Neural Network model\n",
    "model_one_layer= OneLayer(input_size = input_size_1, hidden_size = 50, output_size = num_classes_1).to(DEVICE)\n",
    "#Our loss function will be cross entropy since we are getting a probability distribution\n",
    "loss_1 = torch.nn.CrossEntropyLoss()\n",
    "#Here we are going to use classic stochastic gradient descent without any special optimizations\n",
    "optimizer_1 = torch.optim.SGD(model_one_layer.parameters(), lr= learning_rate_1)\n",
    "start_1 = time.time()\n",
    "training_loss_1, training_accuracy_1, test_loss_1, test_accuracy_1 = training_loop(train_loader, test_loader, \n",
    "num_epochs_1, model_one_layer, loss_1,optimizer_1)\n",
    "\n",
    "end_1 = time.time()\n",
    "total_time = end_1 - start_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dab7d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden.weight torch.Size([50, 784])\n",
      "hidden.bias torch.Size([50])\n",
      "output.weight torch.Size([10, 50])\n",
      "output.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_one_layer.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a8d7a",
   "metadata": {},
   "source": [
    "## SoftMoE implementation  \n",
    "Below we have the first attempt at a SoftMoE implementation. This will pass data through all the experts and a gating mechanism which will then aggregate the output based on probabilities from the gating mechanism. This takes the form  \n",
    "$\\begin{equation}\\sum_i^NG_i(x)E_i(x)\\end{equation}.$  \n",
    "Where $G_i(x)$ is the output from the gating mechanism for the ith expert and $E_i(x)$ is the output from the ith expert. For our first implementation we will have one layer with only a few experts that are then aggregated to produce an output as represented in the image below (without top-k) which is cited [here](http://example.comhttps://apxml.com/posts/how-to-implement-moe-pytorch)  \n",
    "![Architecture](SoftMoe.png \"SoftMoE architecture\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
