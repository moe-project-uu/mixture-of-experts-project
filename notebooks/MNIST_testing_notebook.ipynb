{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bcc396",
   "metadata": {},
   "source": [
    "## Notebook for testing MoE with MNIST  \n",
    "Main objective here is to figure out how to get the gradients to go through the loss function using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11921873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\caleb\\\\OneDrive - Uppsala universitet\\\\Fall 2025\\\\Projects Course\\\\mixture-of-experts-organization\\\\mixture-of-experts-project', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\python313.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\caleb\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for the disk_memoize function\n",
    "import pickle\n",
    "import hashlib\n",
    "from functools import wraps\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add scripts folder path so I can get load_mnist\n",
    "repo_root = os.path.abspath(\"..\")  # one level up from /notebook\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "from scripts.MNIST import load_mnist\n",
    "print(sys.path)\n",
    "\n",
    "#just some basic stuff to set for reproducability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab25eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'glob',\n",
       " 'imageio',\n",
       " 'load_mnist',\n",
       " 'np']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(load_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8e5d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving test images\n",
      "Retrieving train images\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, test_loader\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#get the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m train_loader, test_loader = \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(linear)\u001b[39m\n\u001b[32m     20\u001b[39m test_dataset = torch.utils.data.TensorDataset(xtest, ytest)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#Making a dataloader for this specific CNN which is a wrapper around the Dataset for easy use\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m train_loader = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#make the batch size for the test DataLoader the size of the dataset for evaluation.\u001b[39;00m\n\u001b[32m     24\u001b[39m test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = ytest.shape[\u001b[32m0\u001b[39m], shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    390\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\sampler.py:156\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    152\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m     )\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "#want to get the data in a linear format becuase our simple MoE will be with linear layers\n",
    "def get_data(linear = True):\n",
    "    #get the train and test data from the dataset\n",
    "    xtrain,ytrain,xtest,ytest = load_mnist.load_mnist()\n",
    "    print(xtrain)\n",
    "    #if we want to work with flattened/ linear input\n",
    "    if linear:\n",
    "        xtrain = torch.Tensor(xtrain).to(DEVICE)\n",
    "        ytrain = torch.Tensor(ytrain).to(DEVICE)\n",
    "        xtest = torch.Tensor(xtest).to(DEVICE)\n",
    "        ytest = torch.Tensor(ytest).to(DEVICE)\n",
    "    else:\n",
    "        #converting to Tensors for easy PyTorch implementation and reshape for a CNN\n",
    "        xtrain = torch.Tensor(xtrain).reshape(60000, 1,28,28).to(DEVICE)\n",
    "        ytrain = torch.Tensor(ytrain).to(DEVICE)\n",
    "        xtest = torch.Tensor(xtest).reshape(10000, 1,28,28).to(DEVICE)\n",
    "        ytest = torch.Tensor(ytest).to(DEVICE)\n",
    "    #first we want to put our data in a pytorch dataset so we can mini batch and enumerate through it later more easily\n",
    "    train_dataset = torch.utils.data.TensorDataset(xtrain, ytrain)\n",
    "    test_dataset = torch.utils.data.TensorDataset(xtest, ytest)\n",
    "    #Making a dataloader for this specific CNN which is a wrapper around the Dataset for easy use\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    #make the batch size for the test DataLoader the size of the dataset for evaluation.\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = ytest.shape[0], shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "#get the data\n",
    "train_loader, test_loader = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943de75d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
